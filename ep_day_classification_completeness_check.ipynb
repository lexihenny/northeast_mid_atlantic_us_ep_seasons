{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13353ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import os,errno\n",
    "import sys\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy.ndimage.measurements import label\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import geopy.distance\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dff7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script checks the day classifications for completeness.  It turns out, there are some days left out\n",
    "#(when there is no precip anywhere...just a few days really).  Also, there are a few duplicated, when \n",
    "#there are equal amounts of precip from different categories (typically small amounts and 2 categories).\n",
    "#This script corrects those duplicated by making the attribution to the more meaningful weather type \n",
    "#(i.e., pure extreme IVT instead of unspecified, or TC - AR combination instead of pure TC)\n",
    "\n",
    "#NOTE: For EP days, this does not apply!  The above was for whole climatology.\n",
    "\n",
    "yrs_neusa=np.arange(1979,2020,1)\n",
    "season='summer'\n",
    "for i in range(1,len(yrs_neusa)):\n",
    "    year=yrs_neusa[i]\n",
    "    if season=='winter':\n",
    "        if year%4==0:\n",
    "            feb_length=29\n",
    "        else:\n",
    "            feb_length=28\n",
    "        base_date_1=dt.datetime(year-1,12,1,6)\n",
    "        dates_list_1=[base_date_1+dt.timedelta(days=x) for x in range(31)]\n",
    "\n",
    "        base_date_2=dt.datetime(year,1,1,6)\n",
    "        dates_list_2=[base_date_2+dt.timedelta(days=x) for x in range(31+feb_length)]\n",
    "\n",
    "        dates_list=dates_list_1+dates_list_2\n",
    "\n",
    "    if season=='spring':\n",
    "        base_date=dt.datetime(year,3,1,6)\n",
    "        dates_list=[base_date+dt.timedelta(days=x) for x in range(31+30+31)]\n",
    "\n",
    "    if season=='summer':\n",
    "        base_date=dt.datetime(year,6,1,6)\n",
    "        dates_list=[base_date+dt.timedelta(days=x) for x in range(30+31+31)]\n",
    "\n",
    "    if season=='fall':\n",
    "        base_date=dt.datetime(year,9,1,6)\n",
    "        dates_list=[base_date+dt.timedelta(days=x) for x in range(30+31+30)]\n",
    "        \n",
    "    ds=xr.open_dataset(dir+'day_classifications_neusa_'+season+'_'+str(year)+'.nc')\n",
    "    dates_t1_all=pd.DatetimeIndex(ds['dates_t1_all'].values)\n",
    "    dates_t2_all=pd.DatetimeIndex(ds['dates_t2_all'].values)\n",
    "    dates_t3_all=pd.DatetimeIndex(ds['dates_t3_all'].values)\n",
    "    dates_t4_all=pd.DatetimeIndex(ds['dates_t4_all'].values)\n",
    "    dates_t5_all=pd.DatetimeIndex(ds['dates_t5_all'].values)\n",
    "    dates_t6_all=pd.DatetimeIndex(ds['dates_t6_all'].values)\n",
    "    dates_t7_all=pd.DatetimeIndex(ds['dates_t7_all'].values)\n",
    "    dates_t8_all=pd.DatetimeIndex(ds['dates_t8_all'].values)\n",
    "    dates_t9_all=pd.DatetimeIndex(ds['dates_t9_all'].values)\n",
    "    dates_t10_all=pd.DatetimeIndex(ds['dates_t10_all'].values)\n",
    "    dates_t11_all=pd.DatetimeIndex(ds['dates_t11_all'].values)\n",
    "    \n",
    "    lists=[dates_t1_all,dates_t2_all,dates_t3_all,dates_t4_all,dates_t5_all,dates_t6_all,dates_t7_all,dates_t8_all,dates_t9_all,dates_t10_all,dates_t11_all]\n",
    "    for j in range(len(lists)):\n",
    "        if j==0:\n",
    "            dates_all=lists[j]\n",
    "        else:\n",
    "            dates_all=dates_all.append(lists[j])\n",
    "    dates_all=dates_all.sort_values()\n",
    "    \n",
    "    \n",
    "    dates_ignored=[x for x in dates_list if x not in dates_all]\n",
    "    dates_dup=[x for x in dates_list if len([y for y in dates_all if y==x])>1]\n",
    "    for j in range(len(dates_all.unique())):\n",
    "        if dates_all.unique()[j] in dates_dup:\n",
    "            if dates_all[j] in dates_t11_all:\n",
    "                t11_values=dates_t11_all.values\n",
    "                removed=[x for x in t11_values if x!=pd.to_datetime(dates_all.unique()[j])]\n",
    "                dates_t11_all=pd.DatetimeIndex(removed)\n",
    "            elif dates_all[j] in dates_t8_all:\n",
    "                t8_values=dates_t8_all.values\n",
    "                removed=[x for x in t8_values if x!=pd.to_datetime(dates_all.unique()[j])]\n",
    "                dates_t8_all=pd.DatetimeIndex(removed)\n",
    "            elif dates_all[j] in dates_t1_all:\n",
    "                t1_values=dates_t1_all.values\n",
    "                removed=[x for x in t1_values if x!=pd.to_datetime(dates_all.unique()[j])]\n",
    "                dates_t1_all=pd.DatetimeIndex(removed)\n",
    "            elif dates_all[j] in dates_t4_all:\n",
    "                t4_values=dates_t4_all.values\n",
    "                removed=[x for x in t4_values if x!=pd.to_datetime(dates_all.unique()[j])]\n",
    "                dates_t4_all=pd.DatetimeIndex(removed)\n",
    "    \n",
    "    lists=[dates_t1_all,dates_t2_all,dates_t3_all,dates_t4_all,dates_t5_all,dates_t6_all,dates_t7_all,dates_t8_all,dates_t9_all,dates_t10_all,dates_t11_all]\n",
    "    for j in range(len(lists)):\n",
    "        if j==0:\n",
    "            dates_all=lists[j]\n",
    "        else:\n",
    "            dates_all=dates_all.append(lists[j])\n",
    "    dates_all=dates_all.sort_values()\n",
    "    \n",
    "    print(len(dates_all))\n",
    "\n",
    "    dates_ignored=[x for x in dates_list if x not in dates_all]\n",
    "    #print(dates_ignored)\n",
    "    dates_dup=[x for x in dates_list if len([y for y in dates_all if y==x])>1]\n",
    "    #print(dates_dup)\n",
    "    \n",
    "if 1==1:\n",
    "    \n",
    "    dk=xr.Dataset()\n",
    "    dk['dates_t1_all']=(('time1'),dates_t1_all)\n",
    "    dk['dates_t2_all']=(('time2'),dates_t2_all)\n",
    "    dk['dates_t3_all']=(('time3'),dates_t3_all)\n",
    "    dk['dates_t4_all']=(('time4'),dates_t4_all)\n",
    "    dk['dates_t5_all']=(('time5'),dates_t5_all)\n",
    "    dk['dates_t6_all']=(('time6'),dates_t6_all)\n",
    "    dk['dates_t7_all']=(('time7'),dates_t7_all)\n",
    "    dk['dates_t8_all']=(('time8'),dates_t8_all)\n",
    "    dk['dates_t9_all']=(('time9'),dates_t9_all)\n",
    "    dk['dates_t10_all']=(('time10'),dates_t10_all)\n",
    "    dk['dates_t11_all']=(('time11'),dates_t11_all)\n",
    "\n",
    "    dk.coords['time1']=np.arange(len(dates_t1_all))\n",
    "    dk.coords['time2']=np.arange(len(dates_t2_all))\n",
    "    dk.coords['time3']=np.arange(len(dates_t3_all))\n",
    "    dk.coords['time4']=np.arange(len(dates_t4_all))\n",
    "    dk.coords['time5']=np.arange(len(dates_t5_all))\n",
    "    dk.coords['time6']=np.arange(len(dates_t6_all))\n",
    "    dk.coords['time7']=np.arange(len(dates_t7_all))\n",
    "    dk.coords['time8']=np.arange(len(dates_t8_all))\n",
    "    dk.coords['time9']=np.arange(len(dates_t9_all))\n",
    "    dk.coords['time10']=np.arange(len(dates_t10_all))\n",
    "    dk.coords['time11']=np.arange(len(dates_t11_all))\n",
    "\n",
    "    try:\n",
    "        os.remove(dir+'day_classifications_neusa_'+season+'_'+str(year)+'.nc')\n",
    "    except OSError:\n",
    "        pass\n",
    "    dk.to_netcdf(dir+'day_classifications_neusa_'+season+'_'+str(year)+'.nc',mode='w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11302a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For EP day classifications (by which wtype produces most *extreme* precip)\n",
    "season='fall'\n",
    "thresh_choose=99\n",
    "area_threshold_choose=80\n",
    "season_choose=season\n",
    "\n",
    "ds=xr.open_dataset(dir+'extreme_days_ghcnd_'+str(thresh_choose)+'_'+str(area_threshold_choose)+'_'+season_choose+'.nc')\n",
    "\n",
    "lats=ds['lats'].values.tolist()\n",
    "lons=ds['lons'].values.tolist()\n",
    "lons=[x+360. for x in lons]\n",
    "dates=ds['dates'].values\n",
    "dates_unique=list(set(dates))\n",
    "dates_unique=pd.DatetimeIndex(dates_unique).sort_values()\n",
    "stations=ds['stations'].values.tolist()\n",
    "obs=ds['obs'].values.tolist()\n",
    "years=[x.year for x in dates_unique]\n",
    "print(years)\n",
    "\n",
    "\n",
    "if 1==1:\n",
    "    ds=xr.open_dataset(dir+'day_classifications_neusa_'+season+'_ep_days'+'.nc')\n",
    "    dates_t1_all=pd.DatetimeIndex(ds['dates_t1_all'].values)\n",
    "    dates_t2_all=pd.DatetimeIndex(ds['dates_t2_all'].values)\n",
    "    dates_t3_all=pd.DatetimeIndex(ds['dates_t3_all'].values)\n",
    "    dates_t4_all=pd.DatetimeIndex(ds['dates_t4_all'].values)\n",
    "    dates_t5_all=pd.DatetimeIndex(ds['dates_t5_all'].values)\n",
    "    dates_t6_all=pd.DatetimeIndex(ds['dates_t6_all'].values)\n",
    "    dates_t7_all=pd.DatetimeIndex(ds['dates_t7_all'].values)\n",
    "    dates_t8_all=pd.DatetimeIndex(ds['dates_t8_all'].values)\n",
    "    dates_t9_all=pd.DatetimeIndex(ds['dates_t9_all'].values)\n",
    "    dates_t10_all=pd.DatetimeIndex(ds['dates_t10_all'].values)\n",
    "    dates_t11_all=pd.DatetimeIndex(ds['dates_t11_all'].values)\n",
    "\n",
    "    lists=[dates_t1_all,dates_t2_all,dates_t3_all,dates_t4_all,dates_t5_all,dates_t6_all,dates_t7_all,dates_t8_all,dates_t9_all,dates_t10_all,dates_t11_all]\n",
    "    for j in range(len(lists)):\n",
    "        if j==0:\n",
    "            dates_all=lists[j]\n",
    "        else:\n",
    "            dates_all=dates_all.append(lists[j])\n",
    "    dates_all=dates_all.sort_values()\n",
    "    \n",
    "    \n",
    "    dates_ignored=[x for x in dates_unique if x not in dates_all]\n",
    "    dates_dup=[x for x in dates_unique if len([y for y in dates_all if y==x])>1]\n",
    "    \n",
    "    print(dates_ignored)\n",
    "    print(dates_dup)\n",
    "    for j in range(len(dates_all.unique())):\n",
    "        if dates_all.unique()[j] in dates_dup:\n",
    "            if dates_all[j] in dates_t11_all:\n",
    "                t11_values=dates_t11_all.values\n",
    "                removed=[x for x in t11_values if x!=pd.to_datetime(dates_all.unique()[j])]\n",
    "                dates_t11_all=pd.DatetimeIndex(removed)\n",
    "            elif dates_all[j] in dates_t8_all:\n",
    "                t8_values=dates_t8_all.values\n",
    "                removed=[x for x in t8_values if x!=pd.to_datetime(dates_all.unique()[j])]\n",
    "                dates_t8_all=pd.DatetimeIndex(removed)\n",
    "            elif dates_all[j] in dates_t1_all:\n",
    "                t1_values=dates_t1_all.values\n",
    "                removed=[x for x in t1_values if x!=pd.to_datetime(dates_all.unique()[j])]\n",
    "                dates_t1_all=pd.DatetimeIndex(removed)\n",
    "            elif dates_all[j] in dates_t4_all:\n",
    "                t4_values=dates_t4_all.values\n",
    "                removed=[x for x in t4_values if x!=pd.to_datetime(dates_all.unique()[j])]\n",
    "                dates_t4_all=pd.DatetimeIndex(removed)\n",
    "    \n",
    "    lists=[dates_t1_all,dates_t2_all,dates_t3_all,dates_t4_all,dates_t5_all,dates_t6_all,dates_t7_all,dates_t8_all,dates_t9_all,dates_t10_all,dates_t11_all]\n",
    "    for j in range(len(lists)):\n",
    "        if j==0:\n",
    "            dates_all=lists[j]\n",
    "        else:\n",
    "            dates_all=dates_all.append(lists[j])\n",
    "    dates_all=dates_all.sort_values()\n",
    "    \n",
    "    print(len(dates_all))\n",
    "\n",
    "    dates_ignored=[x for x in dates_unique if x not in dates_all]\n",
    "    print(dates_ignored)\n",
    "    dates_dup=[x for x in dates_unique if len([y for y in dates_all if y==x])>1]\n",
    "    print(dates_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db58a7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-08-08 06:00:00'], dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    \n",
    "    dk=xr.Dataset()\n",
    "    dk['dates_t1_all']=(('time1'),dates_t1_all)\n",
    "    dk['dates_t2_all']=(('time2'),dates_t2_all)\n",
    "    dk['dates_t3_all']=(('time3'),dates_t3_all)\n",
    "    dk['dates_t4_all']=(('time4'),dates_t4_all)\n",
    "    dk['dates_t5_all']=(('time5'),dates_t5_all)\n",
    "    dk['dates_t6_all']=(('time6'),dates_t6_all)\n",
    "    dk['dates_t7_all']=(('time7'),dates_t7_all)\n",
    "    dk['dates_t8_all']=(('time8'),dates_t8_all)\n",
    "    dk['dates_t9_all']=(('time9'),dates_t9_all)\n",
    "    dk['dates_t10_all']=(('time10'),dates_t10_all)\n",
    "    dk['dates_t11_all']=(('time11'),dates_t11_all)\n",
    "\n",
    "    dk.coords['time1']=np.arange(len(dates_t1_all))\n",
    "    dk.coords['time2']=np.arange(len(dates_t2_all))\n",
    "    dk.coords['time3']=np.arange(len(dates_t3_all))\n",
    "    dk.coords['time4']=np.arange(len(dates_t4_all))\n",
    "    dk.coords['time5']=np.arange(len(dates_t5_all))\n",
    "    dk.coords['time6']=np.arange(len(dates_t6_all))\n",
    "    dk.coords['time7']=np.arange(len(dates_t7_all))\n",
    "    dk.coords['time8']=np.arange(len(dates_t8_all))\n",
    "    dk.coords['time9']=np.arange(len(dates_t9_all))\n",
    "    dk.coords['time10']=np.arange(len(dates_t10_all))\n",
    "    dk.coords['time11']=np.arange(len(dates_t11_all))\n",
    "\n",
    "    try:\n",
    "        os.remove(dir+'day_classifications_neusa_'+season+'_ep_days'+'.nc')\n",
    "    except OSError:\n",
    "        pass\n",
    "    dk.to_netcdf(dir+'day_classifications_neusa_'+season+'_ep_days'+'.nc',mode='w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c8d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
