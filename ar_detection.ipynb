{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import os,errno\n",
    "import sys\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy.ndimage.measurements import label\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import geopy.distance\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taiwan bounds: 0-50 N,80-160 E\n",
    "#NEUSA bounds: 10-60 N,30-115 W\n",
    "#These are large enough that an AR invading the NEUSA or Taiwan would be detected - i.e. >2000 km on all sides\n",
    "#ds=xr.open_dataset(dir+'ls_extreme_rain_taiwan.nc')\n",
    "#dates=ds.large_scale_extreme_days\n",
    "\n",
    "#dz2=xr.open_dataset(dir+'ivt_basics_neusa_90.nc')\n",
    "#longitude_sub=dz2.longitude.values\n",
    "ds2=xr.open_dataset(dir+'ivt_basics_neusa.nc')#change this threshold for sensitivity testing #_95_summer\n",
    "#ds2['longitude']=longitude_sub\n",
    "\n",
    "#Winter  425.82147\n",
    "#Spring 448.2696\n",
    "#Summer 534.098\n",
    "#Fall 528.6943\n",
    "#warm 531.6989\n",
    "\n",
    "ivt_threshold=531.6989\n",
    "\n",
    "ivt_mag=ds2['ivt_mag']\n",
    "ivtx=ds2['ivtx']\n",
    "ivty=ds2['ivty']\n",
    "lons_full=ivt_mag.longitude.values\n",
    "lats_full=ivt_mag.latitude.values\n",
    "print(ivt_mag)\n",
    "\n",
    "lat_range=np.arange(0,60,0.25)\n",
    "lon_range=np.arange(-140,-110,0.25)\n",
    "\n",
    "if 1==0:\n",
    "    ds3=xr.open_dataset(dir+'era_5_fall_u_850_neusa.nc')\n",
    "    u_850=ds3['u']#.sel(latitude=lat_range,longitude=lon_range)\n",
    "    ds4=xr.open_dataset(dir+'era_5_fall_v_850_neusa.nc')\n",
    "    v_850=ds4['v']#.sel(latitude=lat_range,longitude=lon_range)\n",
    "    ds5=xr.open_dataset(dir+'era_5_fall_mslp_neusa.nc')\n",
    "    print(ds5)\n",
    "    slp=ds5['msl']#.sel(latitude=lat_range,longitude=lon_range)/100.\n",
    "\n",
    "    ds6=xr.open_dataset(dir+'era_5_fall_sfc_remnants_neusa.nc')\n",
    "    ds6['longitude']=ds3.longitude.values\n",
    "    print(ds6)\n",
    "    slp_2=ds6['mslp']#.sel(latitude=lat_range,longitude=lon_range)\n",
    "    ds7=xr.open_dataset(dir+'era_5_fall_pl_remnants_neusa.nc')\n",
    "    ds7['longitude']=ds3.longitude.values\n",
    "    u_850_2=ds7['u']#.sel(latitude=lat_range,longitude=lon_range)\n",
    "    v_850_2=ds7['v']#.sel(latitude=lat_range,longitude=lon_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u_850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset(dir+'extreme_days_ghcnd_99station_80area95.nc')\n",
    "lats=ds['lats'].values.tolist()\n",
    "lons=ds['lons'].values.tolist()\n",
    "lons=[x+360. for x in lons]\n",
    "dates=ds['dates'].values\n",
    "dates_unique=list(set(dates))\n",
    "dates_unique=pd.DatetimeIndex(dates_unique).sort_values()\n",
    "stations=ds['stations'].values.tolist()\n",
    "obs=ds['obs'].values.tolist()\n",
    "print(dates)\n",
    "\n",
    "ds1=xr.open_dataset(dir+'station_numbers_95.nc')\n",
    "lats1=ds1['lats']#use these lists for plotting\n",
    "lons1=ds1['lons']+360.\n",
    "stations1=ds1['stations']\n",
    "thresholds=ds1['thresholds']/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import shapely.geometry as sgeom\n",
    "def find_side(ls, side):\n",
    "    \"\"\"\n",
    "    Given a shapely LineString which is assumed to be rectangular, return the\n",
    "    line corresponding to a given side of the rectangle.\n",
    "    \n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = ls.bounds\n",
    "    points = {'left': [(minx, miny), (minx, maxy)],\n",
    "              'right': [(maxx, miny), (maxx, maxy)],\n",
    "              'bottom': [(minx, miny), (maxx, miny)],\n",
    "              'top': [(minx, maxy), (maxx, maxy)],}\n",
    "    return sgeom.LineString(points[side])\n",
    "\n",
    "\n",
    "def lambert_xticks(ax, ticks):\n",
    "    \"\"\"Draw ticks on the bottom x-axis of a Lambert Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[0]\n",
    "    lc = lambda t, n, b: np.vstack((np.zeros(n) + t, np.linspace(b[2], b[3], n))).T\n",
    "    xticks, xticklabels = _lambert_ticks(ax, ticks, 'bottom', lc, te)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels([ax.xaxis.get_major_formatter()(xtick) for xtick in xticklabels])\n",
    "    \n",
    "\n",
    "def lambert_yticks(ax, ticks):\n",
    "    \"\"\"Draw ricks on the left y-axis of a Lamber Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[1]\n",
    "    lc = lambda t, n, b: np.vstack((np.linspace(b[0], b[1], n), np.zeros(n) + t)).T\n",
    "    yticks, yticklabels = _lambert_ticks(ax, ticks, 'left', lc, te)\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([ax.yaxis.get_major_formatter()(ytick) for ytick in yticklabels])\n",
    "def _lambert_ticks(ax, ticks, tick_location, line_constructor, tick_extractor):\n",
    "    \"\"\"Get the tick locations and labels for an axis of a Lambert Conformal projection.\"\"\"\n",
    "    outline_patch = sgeom.LineString(ax.outline_patch.get_path().vertices.tolist())\n",
    "    axis = find_side(outline_patch, tick_location)\n",
    "    n_steps = 30\n",
    "    extent = ax.get_extent(ccrs.PlateCarree())\n",
    "    _ticks = []\n",
    "    for t in ticks:\n",
    "        xy = line_constructor(t, n_steps, extent)\n",
    "        proj_xyz = ax.projection.transform_points(ccrs.Geodetic(), xy[:, 0], xy[:, 1])\n",
    "        xyt = proj_xyz[..., :2]\n",
    "        ls = sgeom.LineString(xyt.tolist())\n",
    "        locs = axis.intersection(ls)\n",
    "        if not locs:\n",
    "            tick = [None]\n",
    "        else:\n",
    "            tick = tick_extractor(locs.xy)\n",
    "        _ticks.append(tick[0])\n",
    "    # Remove ticks that aren't visible:    \n",
    "    ticklabels = copy(ticks)\n",
    "    while True:\n",
    "        try:\n",
    "            index = _ticks.index(None)\n",
    "        except ValueError:\n",
    "            break\n",
    "        _ticks.pop(index)\n",
    "        ticklabels.pop(index)\n",
    "    return _ticks, ticklabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds6=xr.open_dataset(dir+'IBTrACS.NA.v04r00.nc')\n",
    "#print(ds)\n",
    "lat_tc=ds6.lat\n",
    "lon_tc=ds6.lon\n",
    "#nature_tc=ds6.nature\n",
    "ds7=xr.open_dataset(dir+'ibtracs_na_time.nc')\n",
    "years_tc=ds7.years\n",
    "months_tc=ds7.months\n",
    "days_tc=ds7.days\n",
    "hours_tc=ds7.hours\n",
    "nature_tc=ds7.nature#1 if tropical, 0 if not\n",
    "print(nature_tc)\n",
    "print(hours_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473211e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "years=np.arange(1979,2020,1)\n",
    "season='fall'\n",
    "print(years)\n",
    "if season=='winter':\n",
    "    for i in range(1,len(years)):\n",
    "        year=years[i]\n",
    "\n",
    "        if year%4==0:\n",
    "            feb_length=29\n",
    "        else:\n",
    "            feb_length=28\n",
    "        base_date_1=dt.datetime(years[i]-1,12,1,6)\n",
    "        dates_list_1=[base_date_1+dt.timedelta(days=x) for x in range(31)]\n",
    "\n",
    "        base_date_2=dt.datetime(years[i],1,1,6)\n",
    "        dates_list_2=[base_date_2+dt.timedelta(days=x) for x in range(31+feb_length)]\n",
    "\n",
    "        dates_list=dates_list_1+dates_list_2\n",
    "\n",
    "        if i==1:\n",
    "            dates_concat=dates_list\n",
    "        else:\n",
    "            dates_concat=dates_concat+dates_list\n",
    "if season=='spring':\n",
    "    for i in range(len(years)):\n",
    "        year=years[i]\n",
    "        base_date=dt.datetime(year,3,1,6)\n",
    "        dates_list=[base_date+dt.timedelta(days=x) for x in range(31+30+31)]\n",
    "        if i==0:\n",
    "            dates_concat=dates_list\n",
    "        else:\n",
    "            dates_concat=dates_concat+dates_list\n",
    "if season=='summer':\n",
    "    for i in range(len(years)):\n",
    "        year=years[i]\n",
    "        base_date=dt.datetime(year,6,1,6)\n",
    "        dates_list=[base_date+dt.timedelta(days=x) for x in range(30+31+31)]\n",
    "        if i==0:\n",
    "            dates_concat=dates_list\n",
    "        else:\n",
    "            dates_concat=dates_concat+dates_list\n",
    "if season=='fall':\n",
    "    for i in range(len(years)):\n",
    "        year=years[i]\n",
    "        base_date=dt.datetime(year,9,1,6)\n",
    "        dates_list=[base_date+dt.timedelta(days=x) for x in range(30+31+30)]\n",
    "        if i==0:\n",
    "            dates_concat=dates_list\n",
    "        else:\n",
    "            dates_concat=dates_concat+dates_list\n",
    "print(dates_concat)\n",
    "dates_unique=dates_concat\n",
    "#dates_unique=[x for x in dates_unique if x.year==1979]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_unique=[]\n",
    "for i in range(10):\n",
    "    year=2000+i\n",
    "    date_start=dt.datetime(year,9,1,6)\n",
    "    date_range=[date_start+dt.timedelta(days=x) for x in range(91)]\n",
    "    if i==0:\n",
    "        dates_unique=date_range\n",
    "    else:\n",
    "        dates_unique=dates_unique+date_range\n",
    "print(dates_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-japan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First - make dataset containing AR points on all four time steps during these 128 EP days\n",
    "#dates_unique1=dates_unique[0:2]\n",
    "for d in range(len(dates_unique)):\n",
    "#for d in range(2):\n",
    "    date=dates_unique[d]#date is at 6Z automatically.  IVT goes from 6Z on day to 6Z on next day\n",
    "    date_range=[date+dt.timedelta(hours=6*x) for x in range(4)]\n",
    "    date_range=pd.DatetimeIndex(date_range).values#date range for IVT selection\n",
    "    for date in date_range:\n",
    "        print(date)\n",
    "        date=pd.to_datetime(date)\n",
    "        year=date.year\n",
    "        month=date.month\n",
    "        day=date.day\n",
    "        hour=date.hour\n",
    "        ivt_mag_current=ivt_mag.sel(time=date)\n",
    "        ivt_extreme=ivt_mag_current.where(ivt_mag_current>=ivt_threshold)\n",
    "        ivt_extreme_full=ivt_extreme\n",
    "        ivt_ones=ivt_extreme/ivt_extreme\n",
    "        ivt_ones=ivt_ones.fillna(0)\n",
    "        structure = np.ones((3, 3), dtype=np.int)          \n",
    "        labeled_full,ncomponents_full=label(ivt_ones,structure) \n",
    "        labeled_xr_full=xr.zeros_like(ivt_extreme)\n",
    "        labeled_xr_full[:,:]=labeled_full\n",
    "        if d==0 and date==date_range[0]:\n",
    "            labeled_ivt_points=labeled_xr_full\n",
    "        else:\n",
    "            labeled_ivt_points=xr.concat([labeled_ivt_points,labeled_xr_full],dim='time')\n",
    "            \n",
    "lats_tc_list=lat_tc.values.ravel()\n",
    "lons_tc_list=lon_tc.values.ravel()\n",
    "years_tc_list=years_tc.values.ravel()\n",
    "months_tc_list=months_tc.values.ravel()\n",
    "days_tc_list=days_tc.values.ravel()\n",
    "hours_tc_list=hours_tc.values.ravel()\n",
    "nature_tc_list=nature_tc.values.ravel()\n",
    "\n",
    "zipped_tc=list(zip(lats_tc_list,lons_tc_list,years_tc_list,months_tc_list,days_tc_list,hours_tc_list,nature_tc_list))\n",
    "nonzero_tc=[x for x in zipped_tc if x[0]>=0]\n",
    "\n",
    "lat_array=xr.zeros_like(ivt_mag[0,:,:])\n",
    "lon_array=xr.zeros_like(ivt_mag[0,:,:])\n",
    "for i in range(ivt_mag.longitude.size):\n",
    "    lat_array[:,i]=ivt_mag.latitude.values\n",
    "for i in range(ivt_mag.latitude.size):\n",
    "    lon_array[i,:]=ivt_mag.longitude.values\n",
    "    \n",
    "lats_full=ivt_mag.latitude.values\n",
    "lons_full=ivt_mag.longitude.values\n",
    "lon_array_list=lon_array.values.ravel()\n",
    "lat_array_list=lat_array.values.ravel()\n",
    "\n",
    "lats_xr=lat_array.copy()[0::2,0]\n",
    "lons_xr=lon_array.copy()[0,0::2]\n",
    "lats_array_xr=lat_array.copy()[0::2,0::2]\n",
    "lons_array_xr=lon_array.copy()[0::2,0::2]\n",
    "lats_xr_flat=lats_array_xr.values.ravel()\n",
    "lons_xr_flat=lons_array_xr.values.ravel()\n",
    "\n",
    "    \n",
    "zipped_latlon=list(zip(lat_array_list,lon_array_list))\n",
    "\n",
    "for d in range(len(dates_unique)):\n",
    "#for d in range(2):\n",
    "    print(d)\n",
    "    date=dates_unique[d]#date is at 6Z automatically.  IVT goes from 6Z on day to 6Z on next day\n",
    "    date_range=[date+dt.timedelta(hours=6*x) for x in range(4)]\n",
    "    date_range=pd.DatetimeIndex(date_range).values#date range for IVT selection\n",
    "    for date in date_range:\n",
    "        print(date)\n",
    "        date=pd.to_datetime(date)\n",
    "        year=date.year\n",
    "        month=date.month\n",
    "        day=date.day\n",
    "        hour=date.hour\n",
    "        ivt_mag_current=ivt_mag.sel(time=date)\n",
    "        ivtx_current=ivtx.sel(time=date)\n",
    "        ivty_current=ivty.sel(time=date)\n",
    "\n",
    "        ivt_extreme=ivt_mag_current.where(ivt_mag_current>=ivt_threshold)\n",
    "        ivt_extreme_full=ivt_extreme\n",
    "        ivt_ones=ivt_extreme/ivt_extreme\n",
    "        ivt_ones=ivt_ones.fillna(0)\n",
    "        \n",
    "        ###Now load TC data and find regions within a certain radius (currently 500 km) of TC centers\n",
    "        \n",
    "        check_lat_tc_trop_list=[x[0] for x in nonzero_tc if x[2]==year and x[3]==month and x[4]==day and x[5]==hour and x[6]==1]\n",
    "        check_lat_tc_nontrop_list=[x[0] for x in nonzero_tc if x[2]==year and x[3]==month and x[4]==day and x[5]==hour and x[6]==0]\n",
    "        check_lon_tc_trop_list=[x[1] for x in nonzero_tc if x[2]==year and x[3]==month and x[4]==day and x[5]==hour and x[6]==1]\n",
    "        check_lon_tc_nontrop_list=[x[1] for x in nonzero_tc if x[2]==year and x[3]==month and x[4]==day and x[5]==hour and x[6]==0]\n",
    "\n",
    "        #print('A')\n",
    "        \n",
    "        if len(check_lat_tc_trop_list)>0 and len(check_lon_tc_trop_list)>0:\n",
    "            #print('TROP')\n",
    "            for i in range(len(check_lat_tc_trop_list)):\n",
    "                lat_tc_single=check_lat_tc_trop_list[i]\n",
    "                lon_tc_single=check_lon_tc_trop_list[i]\n",
    "                first_elim=[x for x in zipped_latlon if abs(x[0]-lat_tc_single)<5.0 or abs(x[1]-lon_tc_single)<10.0]\n",
    "                select_ball_trop=[x for x in first_elim if geopy.distance.distance((x[0],x[1]),(lat_tc_single,lon_tc_single)).km<500.]    \n",
    "                if i==0:\n",
    "                    all_trop_points=select_ball_trop\n",
    "                else:\n",
    "                    all_trop_points=list(set(all_trop_points+select_ball_trop))\n",
    "            all_trop_pairs=[(x[0],x[1]) for x in all_trop_points]\n",
    "                    \n",
    "        if len(check_lat_tc_nontrop_list)>0 and len(check_lon_tc_nontrop_list)>0:\n",
    "            #print('NONTROP')\n",
    "            for i in range(len(check_lat_tc_nontrop_list)):\n",
    "                lat_tc_single=check_lat_tc_nontrop_list[i]\n",
    "                lon_tc_single=check_lon_tc_nontrop_list[i]\n",
    "                first_elim=[x for x in zipped_latlon if abs(x[0]-lat_tc_single)<5.0 or abs(x[1]-lon_tc_single)<10.0]\n",
    "                select_ball_nontrop=[x for x in first_elim if geopy.distance.distance((x[0],x[1]),(lat_tc_single,lon_tc_single)).km<500.]\n",
    "                if i==0:\n",
    "                    all_nontrop_points=select_ball_nontrop\n",
    "                else:\n",
    "                    all_nontrop_points=list(set(all_nontrop_points+select_ball_nontrop))\n",
    "            all_nontrop_pairs=[(x[0],x[1]) for x in all_nontrop_points]\n",
    "        \n",
    "        labeled_tc_trop=xr.zeros_like(ivt_mag_current)\n",
    "        labeled_tc_nontrop=xr.zeros_like(ivt_mag_current)\n",
    "        for i in range(len(lats_full)):\n",
    "            for j in range(len(lons_full)):\n",
    "                if len(check_lat_tc_trop_list)>0:\n",
    "                    if (lats_full[i],lons_full[j]) in all_trop_pairs:\n",
    "                        labeled_tc_trop[i,j]=1\n",
    "                if len(check_lat_tc_nontrop_list)>0:\n",
    "                    if (lats_full[i],lons_full[j]) in all_nontrop_pairs:\n",
    "                        labeled_tc_nontrop[i,j]=1\n",
    "                    \n",
    "        #print('B')\n",
    "        #print(labeled_tc_trop.max().values)\n",
    "        \n",
    "        structure = np.ones((3, 3), dtype=np.int)          \n",
    "        ivt_ones_ar=ivt_ones.where(labeled_tc_trop==0).fillna(0)\n",
    "        labeled,ncomponents=label(ivt_ones_ar,structure)\n",
    "\n",
    "        #AR length is greatest distance between two points in feature\n",
    "        labeled_xr=xr.zeros_like(ivt_extreme)\n",
    "        labeled_xr[:,:]=labeled\n",
    "\n",
    "        endpoint1_list=[]\n",
    "        endpoint2_list=[]\n",
    "        distance_max_list=[]\n",
    "        mean_width_list=[]\n",
    "        north_component_list=[]\n",
    "        ivt_mag_current=ivt_mag_current[0::2,0::2]\n",
    "        ivtx_current=ivtx_current[0::2,0::2]\n",
    "        ivty_current=ivty_current[0::2,0::2]\n",
    "        labeled_xr_full=labeled_xr\n",
    "        labeled_xr=labeled_xr[0::2,0::2]\n",
    "        labeled_xr_flat=labeled_xr.values.ravel()\n",
    "        \n",
    "        #print('C')\n",
    "        \n",
    "        nums_list=[]\n",
    "        points_boundary_list=[]\n",
    "        lat_first_list=[]\n",
    "        lon_first_list=[]\n",
    "        boundaries_xr=xr.zeros_like(labeled_xr)\n",
    "        area_sum_list=[]\n",
    "\n",
    "        for i in range(ncomponents+1):\n",
    "            select_component=labeled_xr.where(labeled_xr==i)\n",
    "            select_component=select_component-select_component\n",
    "            select_component=select_component+1\n",
    "            num_connected=select_component.sum().values\n",
    "            nums_list.append(num_connected)\n",
    "            \n",
    "        zipped_num=list(zip(np.arange(ncomponents+1),nums_list))\n",
    "        sorted_num=sorted(zipped_num,key=lambda x:x[1])\n",
    "        largest_num=sorted_num[-1][0]\n",
    "        zero_indices=[x[0] for x in sorted_num if x[1]==0]\n",
    "        components_num_list=[x for x in np.arange(ncomponents+1) if x!=largest_num and x not in zero_indices]\n",
    "        \n",
    "        ivt_extreme=ivt_extreme[0::2,0::2]\n",
    "        \n",
    "        ar_timestep=xr.zeros_like(labeled_xr_full)\n",
    "        artc_timestep=xr.zeros_like(labeled_xr_full)\n",
    "        \n",
    "        labeled_full_select=labeled_ivt_points.sel(time=date)\n",
    "        \n",
    "        for i in components_num_list:\n",
    "            labeled_test=labeled_xr.where(labeled_xr==i)\n",
    "            set_number_subset=labeled_full_select.where(labeled_xr_full==i)\n",
    "            set_number_values=set_number_subset.values.flatten().tolist()\n",
    "            set_number_values=[x for x in set_number_values if x>0]\n",
    "            set_number_value=list(set(set_number_values))\n",
    "            set_number_value=set_number_value[0]\n",
    "            corresponding_full_label=labeled_full_select.where(labeled_full_select==set_number_value)\n",
    "            corresponding_full_label=corresponding_full_label/corresponding_full_label\n",
    "            \n",
    "            distance_max=0\n",
    "            labeled_select=labeled_xr.where(labeled_xr==i)\n",
    "            labeled_select=labeled_select/labeled_select\n",
    "            labeled_sum=labeled_select.sum().values\n",
    "            \n",
    "            labeled_full_notc=labeled_full_select.where(labeled_tc_trop==0).fillna(0)\n",
    "            \n",
    "            lats_where=lats_xr.where(labeled_xr==i)\n",
    "            lons_where=lons_xr.where(labeled_xr==i)\n",
    "            min_lat=lats_where.min(skipna=True).values\n",
    "            max_lat=lats_where.max(skipna=True).values\n",
    "            min_lon=lons_where.min(skipna=True).values\n",
    "            max_lon=lons_where.max(skipna=True).values\n",
    "\n",
    "            #print('D')\n",
    "            if labeled_select.sum(skipna=True).values>0:\n",
    "                distance_hyp=geopy.distance.geodesic((min_lat,min_lon),(max_lat,max_lon)).km\n",
    "                if distance_hyp>=2000:#filter out features that could not possibly be long enough\n",
    "                    proceed='no'\n",
    "                    ivtx_extreme=ivtx_current.where(labeled_xr==i)\n",
    "                    ivty_extreme=ivty_current.where(labeled_xr==i)\n",
    "                    ivtx_mean=ivtx_extreme.mean(dim=('latitude','longitude'),skipna=True).values\n",
    "                    ivty_mean=ivty_extreme.mean(dim=('latitude','longitude'),skipna=True).values\n",
    "\n",
    "                    north_component_list.append(ivty_mean)\n",
    "                    area_sum=0\n",
    "                    #print('E')\n",
    "                    \n",
    "                    zipped_label=list(zip(lats_xr_flat,lons_xr_flat,labeled_xr_flat))\n",
    "                    select_component_lat=[x[0] for x in zipped_label if x[2]==i]\n",
    "                    select_component_lon=[x[1] for x in zipped_label if x[2]==i]\n",
    "                    areas=[geopy.distance.distance((x,y),(x,y+0.25)).km*geopy.distance.distance((x,y),(x+0.25,y)).km for x,y in zip(select_component_lat,select_component_lon)]\n",
    "                    area_sum=float(sum(areas))\n",
    "                    \n",
    "                    necessary_length=area_sum/1000.\n",
    "                    #print(necessary_length)\n",
    "                    min_lat=min(select_component_lat)\n",
    "                    max_lat=max(select_component_lat)\n",
    "                    min_lon=min(select_component_lon)\n",
    "                    max_lon=max(select_component_lon)\n",
    "                    \n",
    "                    zipped_coords_1=list(zip(select_component_lat,select_component_lon))\n",
    "                    \n",
    "                    min_lat_select=[x for x in zipped_coords_1 if x[0]==min_lat]\n",
    "                    sorted_lat=sorted(min_lat_select,key=lambda x:x[1])\n",
    "                    minlatminlon=sorted_lat[0]\n",
    "                    \n",
    "                    max_lat_select=[x for x in zipped_coords_1 if x[0]==max_lat]\n",
    "                    sorted_lat=sorted(max_lat_select,key=lambda x:x[1])\n",
    "                    maxlatmaxlon=sorted_lat[-1]\n",
    "                    \n",
    "                    min_lon_select=[x for x in zipped_coords_1 if x[1]==min_lon]\n",
    "                    sorted_lon=sorted(min_lon_select,key=lambda x:x[0])\n",
    "                    minlonminlat=sorted_lon[0]\n",
    "                    \n",
    "                    max_lon_select=[x for x in zipped_coords_1 if x[1]==max_lon]\n",
    "                    sorted_lon=sorted(max_lon_select,key=lambda x:x[0])\n",
    "                    maxlonmaxlat=sorted_lon[-1]\n",
    "                    \n",
    "                    \n",
    "                    dist_1=geopy.distance.distance((minlatminlon[0],minlatminlon[1]),(maxlatmaxlon[0],maxlatmaxlon[1])).km\n",
    "                    dist_2=geopy.distance.distance((minlonminlat[0],minlonminlat[1]),(maxlonmaxlat[0],maxlonmaxlat[1])).km\n",
    "                    \n",
    "                    #print(dist_1,dist_2)\n",
    "                    if dist_1>=necessary_length or dist_2>=necessary_length:\n",
    "                        if dist_1>=2000. or dist_2>=2000.:\n",
    "                            proceed='yes'\n",
    "                            #print('YES')\n",
    "                    \n",
    "                    else:\n",
    "                        for j in range(len(select_component_lat)-1):\n",
    "                            lat_1=select_component_lat[j]\n",
    "                            lon_1=select_component_lon[j]\n",
    "                            for k in range(j+1,len(select_component_lat)):\n",
    "                                lat_2=select_component_lat[k]\n",
    "                                lon_2=select_component_lon[k]\n",
    "                                distance=geopy.distance.distance((lat_1,lon_1),(lat_2,lon_2)).km\n",
    "                                if distance>distance_max:\n",
    "                                    distance_max=distance\n",
    "                            \n",
    "                        #print('F')\n",
    "                        if distance_max>=necessary_length and distance_max>=2000.:\n",
    "                            proceed='yes'\n",
    "                    \n",
    "                    north_component=ivty_mean\n",
    "                    if proceed=='no':# or north_component<50:\n",
    "                        pass\n",
    "                    else:\n",
    "                        #print('G')\n",
    "                        corresponding_full_label_ar=corresponding_full_label.where(labeled_xr_full==i).fillna(0)\n",
    "                        corresponding_full_label_tc=corresponding_full_label.where(labeled_tc_trop==1).fillna(0)\n",
    "                        corresponding_full_label_nontc=corresponding_full_label.where(labeled_tc_nontrop==1).fillna(0)\n",
    "                        corresponding_full_label_tc_flat=corresponding_full_label_tc.values.ravel()\n",
    "                        corresponding_full_label_nontc_flat=corresponding_full_label_nontc.values.ravel()\n",
    "                        #first: region of high IVT component that is AR-qualified\n",
    "                        #next: region of high IVT component that is within TC shield\n",
    "                        #Can these be disconnected?  No, because there would have to be non-AR extreme IVT between TC and AR; but that would be connected to AR, so would belong to AR\n",
    "                        \n",
    "                        zipped_label=list(zip(lat_array_list,lon_array_list,corresponding_full_label_tc_flat,corresponding_full_label_nontc_flat))\n",
    "                        select_component_lat=[x[0] for x in zipped_label if x[2]==i]\n",
    "                        select_component_lon=[x[1] for x in zipped_label if x[2]==i]\n",
    "                        areas=[geopy.distance.distance((x,y),(x,y+0.25)).km*geopy.distance.distance((x,y),(x+0.25,y)).km for x,y in zip(select_component_lat,select_component_lon)]\n",
    "                        area_sum_tc=float(sum(areas))\n",
    "                    \n",
    "                        area_ratio=area_sum_tc/area_sum\n",
    "                        if area_ratio>=1./3.:\n",
    "                            labeled_full=labeled_xr_full.where(labeled_xr_full==i).fillna(0)\n",
    "                            artc_timestep=artc_timestep+labeled_full\n",
    "                        else:\n",
    "                            labeled_full=labeled_xr_full.where(labeled_xr_full==i).fillna(0)\n",
    "                            ar_timestep=ar_timestep+labeled_full\n",
    "                    \n",
    "        ar_timestep=ar_timestep.where(ar_timestep>0)\n",
    "        ar_timestep=ar_timestep/ar_timestep\n",
    "        \n",
    "        artc_timestep=artc_timestep.where(artc_timestep>0)\n",
    "        artc_timestep=artc_timestep/artc_timestep\n",
    "        #print('H')\n",
    "        #sys.exit()\n",
    "        if d==0 and date==date_range[0]:\n",
    "            ar_points=ar_timestep\n",
    "            artc_points=artc_timestep\n",
    "            tc_points_trop=labeled_tc_trop\n",
    "            tc_points_nontrop=labeled_tc_nontrop\n",
    "        else:\n",
    "            ar_points=xr.concat([ar_points,ar_timestep],dim='time')\n",
    "            artc_points=xr.concat([artc_points,artc_timestep],dim='time')\n",
    "            tc_points_trop=xr.concat([tc_points_trop,labeled_tc_trop],dim='time')\n",
    "            tc_points_nontrop=xr.concat([tc_points_nontrop,labeled_tc_nontrop],dim='time')\n",
    "\n",
    "            \n",
    "dk=xr.Dataset()\n",
    "\n",
    "dk['ar']=(('time','latitude','longitude'),ar_points)\n",
    "dk['artc']=(('time','latitude','longitude'),artc_points)\n",
    "dk['tc_trop']=(('time','latitude','longitude'),tc_points_trop)\n",
    "dk['tc_nontrop']=(('time','latitude','longitude'),tc_points_nontrop)\n",
    "dk['labeled']=(('time','latitude','longitude'),labeled_ivt_points)\n",
    "\n",
    "dk.coords['time']=ar_points.time\n",
    "dk.coords['latitude']=ar_points.latitude\n",
    "dk.coords['longitude']=ar_points.longitude\n",
    "#A->B, B->C, G->H\n",
    "try:\n",
    "    #os.remove(dir+'neusa_ar_points_test_var95const_ALL_2000_2009.nc')\n",
    "    os.remove(dir+'neusa_ar_points_fallwarm_var95const.nc')#done: 90,925,95,95const\n",
    "except OSError:\n",
    "    pass\n",
    "#dk.to_netcdf(dir+'neusa_ar_points_test_var95const_ALL_2000_2009.nc',mode='w',format='NETCDF4')\n",
    "dk.to_netcdf(dir+'neusa_ar_points_fallwarm_var95const.nc',mode='w',format='NETCDF4')\n",
    "#original = _test\n",
    "#area condition for extended TC moisture flux = _test_elim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-royal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
