{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import os,errno\n",
    "import sys\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy.ndimage.measurements import label\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import geopy.distance\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to draw grid lines on Lambert Conformal projection; \n",
    "#CREDIT ajdawson on GitHub https://gist.github.com/ajdawson/dd536f786741e987ae4e\n",
    "from copy import copy\n",
    "import shapely.geometry as sgeom\n",
    "def find_side(ls, side):\n",
    "    \"\"\"\n",
    "    Given a shapely LineString which is assumed to be rectangular, return the\n",
    "    line corresponding to a given side of the rectangle.\n",
    "    \n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = ls.bounds\n",
    "    points = {'left': [(minx, miny), (minx, maxy)],\n",
    "              'right': [(maxx, miny), (maxx, maxy)],\n",
    "              'bottom': [(minx, miny), (maxx, miny)],\n",
    "              'top': [(minx, maxy), (maxx, maxy)],}\n",
    "    return sgeom.LineString(points[side])\n",
    "\n",
    "\n",
    "def lambert_xticks(ax, ticks):\n",
    "    \"\"\"Draw ticks on the bottom x-axis of a Lambert Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[0]\n",
    "    lc = lambda t, n, b: np.vstack((np.zeros(n) + t, np.linspace(b[2], b[3], n))).T\n",
    "    xticks, xticklabels = _lambert_ticks(ax, ticks, 'bottom', lc, te)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels([ax.xaxis.get_major_formatter()(xtick) for xtick in xticklabels])\n",
    "    \n",
    "\n",
    "def lambert_yticks(ax, ticks):\n",
    "    \"\"\"Draw ricks on the left y-axis of a Lamber Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[1]\n",
    "    lc = lambda t, n, b: np.vstack((np.linspace(b[0], b[1], n), np.zeros(n) + t)).T\n",
    "    yticks, yticklabels = _lambert_ticks(ax, ticks, 'left', lc, te)\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([ax.yaxis.get_major_formatter()(ytick) for ytick in yticklabels])\n",
    "def _lambert_ticks(ax, ticks, tick_location, line_constructor, tick_extractor):\n",
    "    \"\"\"Get the tick locations and labels for an axis of a Lambert Conformal projection.\"\"\"\n",
    "    outline_patch = sgeom.LineString(ax.outline_patch.get_path().vertices.tolist())\n",
    "    axis = find_side(outline_patch, tick_location)\n",
    "    n_steps = 30\n",
    "    extent = ax.get_extent(ccrs.PlateCarree())\n",
    "    _ticks = []\n",
    "    for t in ticks:\n",
    "        xy = line_constructor(t, n_steps, extent)\n",
    "        proj_xyz = ax.projection.transform_points(ccrs.Geodetic(), xy[:, 0], xy[:, 1])\n",
    "        xyt = proj_xyz[..., :2]\n",
    "        ls = sgeom.LineString(xyt.tolist())\n",
    "        locs = axis.intersection(ls)\n",
    "        if not locs:\n",
    "            tick = [None]\n",
    "        else:\n",
    "            tick = tick_extractor(locs.xy)\n",
    "        _ticks.append(tick[0])\n",
    "    # Remove ticks that aren't visible:    \n",
    "    ticklabels = copy(ticks)\n",
    "    while True:\n",
    "        try:\n",
    "            index = _ticks.index(None)\n",
    "        except ValueError:\n",
    "            break\n",
    "        _ticks.pop(index)\n",
    "        ticklabels.pop(index)\n",
    "    return _ticks, ticklabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1=xr.open_dataset(dir+'station_numbers_95.nc')\n",
    "lats_station=ds1['lats'].values.tolist()#use these lists for plotting\n",
    "lons_station=ds1['lons'].values.tolist()\n",
    "stations_station=ds1['stations'].values.tolist()\n",
    "thresholds_fall_99=ds1['thresholds_fall_99']/10.\n",
    "thresholds_fall_99=thresholds_fall_99.values.tolist()\n",
    "thresholds_winter_99=ds1['thresholds_winter_99']/10.\n",
    "thresholds_winter_99=thresholds_winter_99.values.tolist()\n",
    "thresholds_spring_99=ds1['thresholds_spring_99']/10.\n",
    "thresholds_spring_99=thresholds_spring_99.values.tolist()\n",
    "thresholds_summer_99=ds1['thresholds_summer_99']/10.\n",
    "thresholds_summer_99=thresholds_summer_99.values.tolist()\n",
    "\n",
    "thresholds_fall_95=ds1['thresholds_fall_95']/10.\n",
    "thresholds_fall_95=thresholds_fall_95.values.tolist()\n",
    "thresholds_winter_95=ds1['thresholds_winter_95']/10.\n",
    "thresholds_winter_95=thresholds_winter_95.values.tolist()\n",
    "thresholds_spring_95=ds1['thresholds_spring_95']/10.\n",
    "thresholds_spring_95=thresholds_spring_95.values.tolist()\n",
    "thresholds_summer_95=ds1['thresholds_summer_95']/10.\n",
    "thresholds_summer_95=thresholds_summer_95.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs_neusa=np.arange(1979,2020,1)\n",
    "annual_rate_t1_list=[]\n",
    "annual_rate_t2_list=[]\n",
    "annual_rate_t3_list=[]\n",
    "annual_rate_t4_list=[]\n",
    "annual_rate_t5_list=[]\n",
    "annual_rate_t6_list=[]\n",
    "annual_rate_t7_list=[]\n",
    "annual_rate_t8_list=[]\n",
    "annual_rate_t9_list=[]\n",
    "annual_rate_t10_list=[]\n",
    "annual_rate_t11_list=[]\n",
    "\n",
    "annual_rate_ar_list=[]\n",
    "annual_rate_tc_list=[]\n",
    "annual_rate_other_list=[]\n",
    "\n",
    "annual_intensity_t1_list=[]\n",
    "annual_intensity_t2_list=[]\n",
    "annual_intensity_t3_list=[]\n",
    "annual_intensity_t4_list=[]\n",
    "annual_intensity_t5_list=[]\n",
    "annual_intensity_t6_list=[]\n",
    "annual_intensity_t7_list=[]\n",
    "annual_intensity_t8_list=[]\n",
    "annual_intensity_t9_list=[]\n",
    "annual_intensity_t10_list=[]\n",
    "annual_intensity_t11_list=[]\n",
    "\n",
    "annual_intensity_ar_list=[]\n",
    "annual_intensity_tc_list=[]\n",
    "annual_intensity_other_list=[]\n",
    "\n",
    "years_t1_list=[]\n",
    "years_t2_list=[]\n",
    "years_t3_list=[]\n",
    "years_t4_list=[]\n",
    "years_t5_list=[]\n",
    "years_t6_list=[]\n",
    "years_t7_list=[]\n",
    "years_t8_list=[]\n",
    "years_t9_list=[]\n",
    "years_t10_list=[]\n",
    "years_t11_list=[]\n",
    "\n",
    "years_ar_list=[]\n",
    "years_tc_list=[]\n",
    "years_other_list=[]\n",
    "\n",
    "\n",
    "lats_t1_list=[]\n",
    "lats_t2_list=[]\n",
    "lats_t3_list=[]\n",
    "lats_t4_list=[]\n",
    "lats_t5_list=[]\n",
    "lats_t6_list=[]\n",
    "lats_t7_list=[]\n",
    "lats_t8_list=[]\n",
    "lats_t9_list=[]\n",
    "lats_t10_list=[]\n",
    "lats_t11_list=[]\n",
    "\n",
    "lats_ar_list=[]\n",
    "lats_tc_list=[]\n",
    "lats_other_list=[]\n",
    "lats_linked_list=[]\n",
    "\n",
    "lons_t1_list=[]\n",
    "lons_t2_list=[]\n",
    "lons_t3_list=[]\n",
    "lons_t4_list=[]\n",
    "lons_t5_list=[]\n",
    "lons_t6_list=[]\n",
    "lons_t7_list=[]\n",
    "lons_t8_list=[]\n",
    "lons_t9_list=[]\n",
    "lons_t10_list=[]\n",
    "lons_t11_list=[]\n",
    "\n",
    "lons_ar_list=[]\n",
    "lons_tc_list=[]\n",
    "lons_other_list=[]\n",
    "lons_linked_list=[]\n",
    "\n",
    "stations_t1_list=[]\n",
    "stations_t2_list=[]\n",
    "stations_t3_list=[]\n",
    "stations_t4_list=[]\n",
    "stations_t5_list=[]\n",
    "stations_t6_list=[]\n",
    "stations_t7_list=[]\n",
    "stations_t8_list=[]\n",
    "stations_t9_list=[]\n",
    "stations_t10_list=[]\n",
    "stations_t11_list=[]\n",
    "\n",
    "stations_tc_list=[]\n",
    "stations_ar_list=[]\n",
    "stations_other_list=[]\n",
    "season='winter'\n",
    "for i in range(1,len(yrs_neusa)):\n",
    "    print(i)\n",
    "    if i>1:\n",
    "        ds.close()\n",
    "    year=yrs_neusa[i]\n",
    "    #ds=xr.open_dataset(dir+'climo_neusa_precip_days_stats_'+str(year)+'.nc')\n",
    "    ds=xr.open_dataset(dir+'climo_neusa_ar_'+season+'_'+str(year)+'.nc')\n",
    "    #print(ds)\n",
    "\n",
    "    lats_pure_ar=ds['lats_pure_ar'].values.tolist()\n",
    "    lons_pure_ar=ds['lons_pure_ar'].values.tolist()\n",
    "    lons_pure_ar=[x-360. for x in lons_pure_ar]\n",
    "    obs_pure_ar=ds['obs_pure_ar'].values.tolist()\n",
    "    dates_pure_ar=ds['dates_pure_ar'].values\n",
    "    stations_pure_ar=ds['stations_pure_ar'].values.tolist()#filenames\n",
    "\n",
    "    lats_pure_tc=ds['lats_pure_tc'].values.tolist()\n",
    "    lons_pure_tc=ds['lons_pure_tc'].values.tolist()\n",
    "    lons_pure_tc=[x-360. for x in lons_pure_tc]\n",
    "    obs_pure_tc=ds['obs_pure_tc'].values.tolist()\n",
    "    dates_pure_tc=ds['dates_pure_tc'].values\n",
    "    stations_pure_tc=ds['stations_pure_tc'].values.tolist()\n",
    "\n",
    "    lats_pure_extreme_ivt=ds['lats_pure_extreme_ivt'].values.tolist()\n",
    "    lons_pure_extreme_ivt=ds['lons_pure_extreme_ivt'].values.tolist()\n",
    "    lons_pure_extreme_ivt=[x-360. for x in lons_pure_extreme_ivt]\n",
    "    obs_pure_extreme_ivt=ds['obs_pure_extreme_ivt'].values.tolist()\n",
    "    dates_pure_extreme_ivt=ds['dates_pure_extreme_ivt'].values\n",
    "    stations_pure_extreme_ivt=ds['stations_pure_extreme_ivt'].values.tolist()\n",
    "\n",
    "    lats_tc_linked_ar=ds['lats_tc_linked_ar'].values.tolist()\n",
    "    lons_tc_linked_ar=ds['lons_tc_linked_ar'].values.tolist()\n",
    "    lons_tc_linked_ar=[x-360. for x in lons_tc_linked_ar]\n",
    "    obs_tc_linked_ar=ds['obs_tc_linked_ar'].values.tolist()\n",
    "    dates_tc_linked_ar=ds['dates_tc_linked_ar'].values\n",
    "    stations_tc_linked_ar=ds['stations_tc_linked_ar'].values.tolist()\n",
    "\n",
    "    lats_tc_remnant_linked_ar=ds['lats_tc_remnant_linked_ar'].values.tolist()\n",
    "    lons_tc_remnant_linked_ar=ds['lons_tc_remnant_linked_ar'].values.tolist()\n",
    "    lons_tc_remnant_linked_ar=[x-360. for x in lons_tc_remnant_linked_ar]\n",
    "    obs_tc_remnant_linked_ar=ds['obs_tc_remnant_linked_ar'].values.tolist()\n",
    "    dates_tc_remnant_linked_ar=ds['dates_tc_remnant_linked_ar'].values\n",
    "    stations_tc_remnant_linked_ar=ds['stations_tc_remnant_linked_ar'].values.tolist()\n",
    "\n",
    "    lats_tc_linked_ivt=ds['lats_tc_linked_ivt'].values.tolist()\n",
    "    lons_tc_linked_ivt=ds['lons_tc_linked_ivt'].values.tolist()\n",
    "    lons_tc_linked_ivt=[x-360. for x in lons_tc_linked_ivt]\n",
    "    obs_tc_linked_ivt=ds['obs_tc_linked_ivt'].values.tolist()\n",
    "    dates_tc_linked_ivt=ds['dates_tc_linked_ivt'].values\n",
    "    stations_tc_linked_ivt=ds['stations_tc_linked_ivt'].values.tolist()\n",
    "\n",
    "    lats_tc_remnant_linked_ivt=ds['lats_tc_remnant_linked_ivt'].values.tolist()\n",
    "    lons_tc_remnant_linked_ivt=ds['lons_tc_remnant_linked_ivt'].values.tolist()\n",
    "    lons_tc_remnant_linked_ivt=[x-360. for x in lons_tc_remnant_linked_ivt]\n",
    "    obs_tc_remnant_linked_ivt=ds['obs_tc_remnant_linked_ivt'].values.tolist()\n",
    "    dates_tc_remnant_linked_ivt=ds['dates_tc_remnant_linked_ivt'].values\n",
    "    stations_tc_remnant_linked_ivt=ds['stations_tc_remnant_linked_ivt'].values.tolist()\n",
    "\n",
    "    lats_tc_remnants=ds['lats_tc_remnants'].values.tolist()\n",
    "    lons_tc_remnants=ds['lons_tc_remnants'].values.tolist()\n",
    "    lons_tc_remnants=[x-360. for x in lons_tc_remnants]\n",
    "    obs_tc_remnants=ds['obs_tc_remnants'].values.tolist()\n",
    "    dates_tc_remnants=ds['dates_tc_remnants'].values\n",
    "    stations_tc_remnants=ds['stations_tc_remnants'].values.tolist()\n",
    "\n",
    "    lats_tc_ar_combo=ds['lats_tc_ar_combo'].values.tolist()\n",
    "    lons_tc_ar_combo=ds['lons_tc_ar_combo'].values.tolist()\n",
    "    lons_tc_ar_combo=[x-360. for x in lons_tc_ar_combo]\n",
    "    obs_tc_ar_combo=ds['obs_tc_ar_combo'].values.tolist()\n",
    "    dates_tc_ar_combo=ds['dates_tc_ar_combo'].values\n",
    "    stations_tc_ar_combo=ds['stations_tc_ar_combo'].values.tolist()\n",
    "\n",
    "    lats_tc_remnant_ar_combo=ds['lats_tc_remnant_ar_combo'].values.tolist()\n",
    "    lons_tc_remnant_ar_combo=ds['lons_tc_remnant_ar_combo'].values.tolist()\n",
    "    lons_tc_remnant_ar_combo=[x-360. for x in lons_tc_remnant_ar_combo]\n",
    "    obs_tc_remnant_ar_combo=ds['obs_tc_remnant_ar_combo'].values.tolist()\n",
    "    dates_tc_remnant_ar_combo=ds['dates_tc_remnant_ar_combo'].values\n",
    "    stations_tc_remnant_ar_combo=ds['stations_tc_remnant_ar_combo'].values.tolist()\n",
    "\n",
    "    lats_other=ds['lats_other'].values.tolist()\n",
    "    lons_other=ds['lons_other'].values.tolist()\n",
    "    lons_other=[x-360. for x in lons_other]\n",
    "    obs_other=ds['obs_other'].values.tolist()\n",
    "    dates_other=ds['dates_other'].values\n",
    "    stations_other=ds['stations_other'].values.tolist()\n",
    "    \n",
    "    zipped_t1=list(zip(dates_pure_ar,lats_pure_ar,lons_pure_ar,obs_pure_ar,stations_pure_ar))\n",
    "    zipped_t2=list(zip(dates_tc_linked_ar,lats_tc_linked_ar,lons_tc_linked_ar,obs_tc_linked_ar,stations_tc_linked_ar))\n",
    "    zipped_t3=list(zip(dates_tc_remnant_linked_ar,lats_tc_remnant_linked_ar,lons_tc_remnant_linked_ar,obs_tc_remnant_linked_ar,stations_tc_remnant_linked_ar))\n",
    "    zipped_t4=list(zip(dates_pure_tc,lats_pure_tc,lons_pure_tc,obs_pure_tc,stations_pure_tc))\n",
    "    zipped_t5=list(zip(dates_tc_ar_combo,lats_tc_ar_combo,lons_tc_ar_combo,obs_tc_ar_combo,stations_tc_ar_combo))\n",
    "    zipped_t6=list(zip(dates_tc_remnant_ar_combo,lats_tc_remnant_ar_combo,lons_tc_remnant_ar_combo,obs_tc_remnant_ar_combo,stations_tc_remnant_ar_combo))\n",
    "    zipped_t7=list(zip(dates_tc_remnants,lats_tc_remnants,lons_tc_remnants,obs_tc_remnants,stations_tc_remnants))\n",
    "    zipped_t8=list(zip(dates_pure_extreme_ivt,lats_pure_extreme_ivt,lons_pure_extreme_ivt,obs_pure_extreme_ivt,stations_pure_extreme_ivt))\n",
    "    zipped_t9=list(zip(dates_tc_linked_ivt,lats_tc_linked_ivt,lons_tc_linked_ivt,obs_tc_linked_ivt,stations_tc_linked_ivt))\n",
    "    zipped_t10=list(zip(dates_tc_remnant_linked_ivt,lats_tc_remnant_linked_ivt,lons_tc_remnant_linked_ivt,obs_tc_remnant_linked_ivt,stations_tc_remnant_linked_ivt))\n",
    "    zipped_t11=list(zip(dates_other,lats_other,lons_other,obs_other,stations_other))\n",
    "\n",
    "    for j in range(len(stations_station)):\n",
    "        station=stations_station[j]\n",
    "        thresh=thresholds_winter_95[j]\n",
    "        lat=lats_station[j]\n",
    "        lon=lons_station[j]\n",
    "        select_station_t1=[x for x in zipped_t1 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t2=[x for x in zipped_t2 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t3=[x for x in zipped_t3 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t4=[x for x in zipped_t4 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t5=[x for x in zipped_t5 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t6=[x for x in zipped_t6 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t7=[x for x in zipped_t7 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t8=[x for x in zipped_t8 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t9=[x for x in zipped_t9 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t10=[x for x in zipped_t10 if x[4]==station and x[3]>=thresh]\n",
    "        select_station_t11=[x for x in zipped_t11 if x[4]==station and x[3]>=thresh]\n",
    "\n",
    "        select_station_ar=select_station_t1+select_station_t2+select_station_t3\n",
    "        select_station_tc=select_station_t4+select_station_t5+select_station_t6+select_station_t7\n",
    "        select_station_other=select_station_t8+select_station_t9+select_station_t10+select_station_t11\n",
    "\n",
    "        if len(select_station_t1)>0:\n",
    "            obs_station_t1=[x[3] for x in select_station_t1]\n",
    "            total_precip_station_t1=sum(obs_station_t1)\n",
    "            annual_rate_t1=total_precip_station_t1\n",
    "            annual_rate_t1_list.append(annual_rate_t1)\n",
    "            lats_t1_list.append(lat)\n",
    "            lons_t1_list.append(lon)\n",
    "            stations_t1_list.append(station)\n",
    "            \n",
    "            years_t1_list.append(year)\n",
    "\n",
    "            mean_intensity_t1=float(sum(obs_station_t1))/float(len(obs_station_t1))\n",
    "            annual_intensity_t1_list.append(mean_intensity_t1)\n",
    "        else:\n",
    "            annual_rate_t1_list.append(0)\n",
    "            years_t1_list.append(year)\n",
    "            stations_t1_list.append(station)\n",
    "\n",
    "        if len(select_station_t2)>0:\n",
    "            obs_station_t2=[x[3] for x in select_station_t2]\n",
    "            total_precip_station_t2=sum(obs_station_t2)\n",
    "            annual_rate_t2=total_precip_station_t2\n",
    "            annual_rate_t2_list.append(annual_rate_t2)\n",
    "            lats_t2_list.append(lat)\n",
    "            lons_t2_list.append(lon)\n",
    "            stations_t2_list.append(station)\n",
    "            \n",
    "            years_t2_list.append(year)\n",
    "\n",
    "            mean_intensity_t2=float(sum(obs_station_t2))/float(len(obs_station_t2))\n",
    "            annual_intensity_t2_list.append(mean_intensity_t2)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t2_list.append(0)\n",
    "            years_t2_list.append(year)\n",
    "            stations_t2_list.append(station)\n",
    "\n",
    "        if len(select_station_t3)>0:\n",
    "            obs_station_t3=[x[3] for x in select_station_t3]\n",
    "            total_precip_station_t3=sum(obs_station_t3)\n",
    "            annual_rate_t3=total_precip_station_t3\n",
    "            annual_rate_t3_list.append(annual_rate_t3)\n",
    "            lats_t3_list.append(lat)\n",
    "            lons_t3_list.append(lon)\n",
    "            stations_t3_list.append(station)\n",
    "            \n",
    "            years_t3_list.append(year)\n",
    "\n",
    "            mean_intensity_t3=float(sum(obs_station_t3))/float(len(obs_station_t3))\n",
    "            annual_intensity_t3_list.append(mean_intensity_t3)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t3_list.append(0)\n",
    "            years_t3_list.append(year)\n",
    "            stations_t3_list.append(station)\n",
    "\n",
    "        if len(select_station_t4)>0:\n",
    "            obs_station_t4=[x[3] for x in select_station_t4]\n",
    "            total_precip_station_t4=sum(obs_station_t4)\n",
    "            annual_rate_t4=total_precip_station_t4\n",
    "            annual_rate_t4_list.append(annual_rate_t4)\n",
    "            lats_t4_list.append(lat)\n",
    "            lons_t4_list.append(lon)\n",
    "            stations_t4_list.append(station)\n",
    "            \n",
    "            years_t4_list.append(year)\n",
    "\n",
    "            mean_intensity_t4=float(sum(obs_station_t4))/float(len(obs_station_t4))\n",
    "            annual_intensity_t4_list.append(mean_intensity_t4)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t4_list.append(0)\n",
    "            years_t4_list.append(year)\n",
    "            stations_t4_list.append(station)\n",
    "\n",
    "        if len(select_station_t5)>0:\n",
    "            obs_station_t5=[x[3] for x in select_station_t5]\n",
    "            total_precip_station_t5=sum(obs_station_t5)\n",
    "            annual_rate_t5=total_precip_station_t5\n",
    "            annual_rate_t5_list.append(annual_rate_t5)\n",
    "            lats_t5_list.append(lat)\n",
    "            lons_t5_list.append(lon)\n",
    "            stations_t5_list.append(station)\n",
    "            \n",
    "            years_t5_list.append(year)\n",
    "\n",
    "            mean_intensity_t5=float(sum(obs_station_t5))/float(len(obs_station_t5))\n",
    "            annual_intensity_t5_list.append(mean_intensity_t5)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t5_list.append(0)\n",
    "            years_t5_list.append(year)\n",
    "            stations_t5_list.append(station)\n",
    "\n",
    "        if len(select_station_t6)>0:\n",
    "            obs_station_t6=[x[3] for x in select_station_t6]\n",
    "            total_precip_station_t6=sum(obs_station_t6)\n",
    "            annual_rate_t6=total_precip_station_t6\n",
    "            annual_rate_t6_list.append(annual_rate_t6)\n",
    "            lats_t6_list.append(lat)\n",
    "            lons_t6_list.append(lon)\n",
    "            stations_t6_list.append(station)\n",
    "            \n",
    "            years_t6_list.append(year)\n",
    "\n",
    "            mean_intensity_t6=float(sum(obs_station_t6))/float(len(obs_station_t6))\n",
    "            annual_intensity_t6_list.append(mean_intensity_t6)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t6_list.append(0)\n",
    "            years_t6_list.append(year)\n",
    "            stations_t6_list.append(station)\n",
    "\n",
    "        if len(select_station_t7)>0:\n",
    "            obs_station_t7=[x[3] for x in select_station_t7]\n",
    "            total_precip_station_t7=sum(obs_station_t7)\n",
    "            annual_rate_t7=total_precip_station_t7\n",
    "            annual_rate_t7_list.append(annual_rate_t7)\n",
    "            lats_t7_list.append(lat)\n",
    "            lons_t7_list.append(lon)\n",
    "            stations_t7_list.append(station)\n",
    "            \n",
    "            years_t7_list.append(year)\n",
    "\n",
    "            mean_intensity_t7=float(sum(obs_station_t7))/float(len(obs_station_t7))\n",
    "            annual_intensity_t7_list.append(mean_intensity_t7)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t7_list.append(0)\n",
    "            years_t7_list.append(year)\n",
    "            stations_t7_list.append(station)\n",
    "\n",
    "        if len(select_station_t8)>0:\n",
    "            obs_station_t8=[x[3] for x in select_station_t8]\n",
    "            total_precip_station_t8=sum(obs_station_t8)\n",
    "            annual_rate_t8=total_precip_station_t8\n",
    "            annual_rate_t8_list.append(annual_rate_t8)\n",
    "            lats_t8_list.append(lat)\n",
    "            lons_t8_list.append(lon)\n",
    "            stations_t8_list.append(station)\n",
    "            \n",
    "            years_t8_list.append(year)\n",
    "\n",
    "            mean_intensity_t8=float(sum(obs_station_t8))/float(len(obs_station_t8))\n",
    "            annual_intensity_t8_list.append(mean_intensity_t8)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t8_list.append(0)\n",
    "            years_t8_list.append(year)\n",
    "            stations_t8_list.append(station)\n",
    "\n",
    "        if len(select_station_t9)>0:\n",
    "            obs_station_t9=[x[3] for x in select_station_t9]\n",
    "            total_precip_station_t9=sum(obs_station_t9)\n",
    "            annual_rate_t9=total_precip_station_t9\n",
    "            annual_rate_t9_list.append(annual_rate_t9)\n",
    "            lats_t9_list.append(lat)\n",
    "            lons_t9_list.append(lon)\n",
    "            stations_t9_list.append(station)\n",
    "            \n",
    "            years_t9_list.append(year)\n",
    "\n",
    "            mean_intensity_t9=float(sum(obs_station_t9))/float(len(obs_station_t9))\n",
    "            annual_intensity_t9_list.append(mean_intensity_t9)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t9_list.append(0)\n",
    "            years_t9_list.append(year)\n",
    "            stations_t9_list.append(station)\n",
    "\n",
    "        if len(select_station_t10)>0:\n",
    "            obs_station_t10=[x[3] for x in select_station_t10]\n",
    "            total_precip_station_t10=sum(obs_station_t10)\n",
    "            annual_rate_t10=total_precip_station_t10\n",
    "            annual_rate_t10_list.append(annual_rate_t10)\n",
    "            lats_t10_list.append(lat)\n",
    "            lons_t10_list.append(lon)\n",
    "            stations_t10_list.append(station)\n",
    "            \n",
    "            years_t10_list.append(year)\n",
    "\n",
    "            mean_intensity_t10=float(sum(obs_station_t10))/float(len(obs_station_t10))\n",
    "            annual_intensity_t10_list.append(mean_intensity_t10)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t10_list.append(0)\n",
    "            years_t10_list.append(year)\n",
    "            stations_t10_list.append(station)\n",
    "\n",
    "        if len(select_station_t11)>0:\n",
    "            obs_station_t11=[x[3] for x in select_station_t11]\n",
    "            total_precip_station_t11=sum(obs_station_t11)\n",
    "            annual_rate_t11=total_precip_station_t11\n",
    "            annual_rate_t11_list.append(annual_rate_t11)\n",
    "            lats_t11_list.append(lat)\n",
    "            lons_t11_list.append(lon)\n",
    "            stations_t11_list.append(station)\n",
    "            \n",
    "            years_t11_list.append(year)\n",
    "\n",
    "            mean_intensity_t11=float(sum(obs_station_t11))/float(len(obs_station_t11))\n",
    "            annual_intensity_t11_list.append(mean_intensity_t11)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_t11_list.append(0)\n",
    "            years_t11_list.append(year)\n",
    "            stations_t11_list.append(station)\n",
    "\n",
    "        if len(select_station_ar)>0:\n",
    "            obs_station_ar=[x[3] for x in select_station_ar]\n",
    "            total_precip_station_ar=sum(obs_station_ar)\n",
    "            annual_rate_ar=total_precip_station_ar\n",
    "            annual_rate_ar_list.append(annual_rate_ar)\n",
    "            lats_ar_list.append(lat)\n",
    "            lons_ar_list.append(lon)\n",
    "            stations_ar_list.append(station)\n",
    "            \n",
    "            years_ar_list.append(year)\n",
    "\n",
    "            mean_intensity_ar=float(sum(obs_station_ar))/float(len(obs_station_ar))\n",
    "            annual_intensity_ar_list.append(mean_intensity_ar)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_ar_list.append(0)\n",
    "            years_ar_list.append(year)\n",
    "            stations_ar_list.append(station)\n",
    "\n",
    "        if len(select_station_tc)>0:\n",
    "            obs_station_tc=[x[3] for x in select_station_tc]\n",
    "            total_precip_station_tc=sum(obs_station_tc)\n",
    "            annual_rate_tc=total_precip_station_tc\n",
    "            annual_rate_tc_list.append(annual_rate_tc)\n",
    "            lats_tc_list.append(lat)\n",
    "            lons_tc_list.append(lon)\n",
    "            stations_tc_list.append(station)\n",
    "            \n",
    "            years_tc_list.append(year)\n",
    "\n",
    "            mean_intensity_tc=float(sum(obs_station_tc))/float(len(obs_station_tc))\n",
    "            annual_intensity_tc_list.append(mean_intensity_tc)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_tc_list.append(0)\n",
    "            years_tc_list.append(year)\n",
    "            stations_tc_list.append(station)\n",
    "\n",
    "        if len(select_station_other)>0:\n",
    "            obs_station_other=[x[3] for x in select_station_other]\n",
    "            total_precip_station_other=sum(obs_station_other)\n",
    "            annual_rate_other=total_precip_station_other\n",
    "            annual_rate_other_list.append(annual_rate_other)\n",
    "            lats_other_list.append(lat)\n",
    "            lons_other_list.append(lon)\n",
    "            stations_other_list.append(station)\n",
    "            \n",
    "            years_other_list.append(year)\n",
    "\n",
    "            mean_intensity_other=float(sum(obs_station_other))/float(len(obs_station_other))\n",
    "            annual_intensity_other_list.append(mean_intensity_other)\n",
    "            \n",
    "        else:\n",
    "            annual_rate_other_list.append(0)\n",
    "            years_other_list.append(year)\n",
    "            stations_other_list.append(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@author: Michael Schramm on GitHub\n",
    "#This function is derived from code originally posted by Sat Kumar Tomer\n",
    "#(satkumartomer@gmail.com)\n",
    "#See also: http://vsp.pnnl.gov/help/Vsample/Design_Trend_Mann_Kendall.htm\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as st\n",
    "def mk_test(x, alpha=0.05):\n",
    "    n = len(x)\n",
    "\n",
    "    # calculate S\n",
    "    s = 0\n",
    "    for k in range(n-1):\n",
    "        for j in range(k+1, n):\n",
    "            s += np.sign(x[j] - x[k])\n",
    "\n",
    "    # calculate the unique data\n",
    "    unique_x, tp = np.unique(x, return_counts=True)\n",
    "    g = len(unique_x)\n",
    "\n",
    "    # calculate the var(s)\n",
    "    if n == g:  # there is no tie\n",
    "        var_s = (n*(n-1)*(2*n+5))/18\n",
    "    else:  # there are some ties in data\n",
    "        var_s = (n*(n-1)*(2*n+5) - np.sum(tp*(tp-1)*(2*tp+5)))/18\n",
    "\n",
    "    if s > 0:\n",
    "        z = (s - 1)/np.sqrt(var_s)\n",
    "    elif s < 0:\n",
    "        z = (s + 1)/np.sqrt(var_s)\n",
    "    else: # s == 0:\n",
    "        z = 0\n",
    "\n",
    "    # calculate the p_value\n",
    "    p = 2*(1-norm.cdf(abs(z)))  # two tail test\n",
    "    h = abs(z) > norm.ppf(1-alpha/2)\n",
    "\n",
    "    if (z < 0) and h:\n",
    "        trend = 'decreasing'\n",
    "    elif (z > 0) and h:\n",
    "        trend = 'increasing'\n",
    "    else:\n",
    "        trend = 'no trend'\n",
    "\n",
    "    return trend, h, p, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-foundation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zipped_t1_total_list=list(zip(years_t1_list,annual_rate_t1_list,stations_t1_list))\n",
    "zipped_t2_total_list=list(zip(years_t2_list,annual_rate_t2_list,stations_t2_list))\n",
    "zipped_t3_total_list=list(zip(years_t3_list,annual_rate_t3_list,stations_t3_list))\n",
    "zipped_t4_total_list=list(zip(years_t4_list,annual_rate_t4_list,stations_t4_list))\n",
    "zipped_t5_total_list=list(zip(years_t5_list,annual_rate_t5_list,stations_t5_list))\n",
    "zipped_t6_total_list=list(zip(years_t6_list,annual_rate_t6_list,stations_t6_list))\n",
    "zipped_t7_total_list=list(zip(years_t7_list,annual_rate_t7_list,stations_t7_list))\n",
    "zipped_t8_total_list=list(zip(years_t8_list,annual_rate_t8_list,stations_t8_list))\n",
    "zipped_t9_total_list=list(zip(years_t9_list,annual_rate_t9_list,stations_t9_list))\n",
    "zipped_t10_total_list=list(zip(years_t10_list,annual_rate_t10_list,stations_t10_list))\n",
    "zipped_t11_total_list=list(zip(years_t11_list,annual_rate_t11_list,stations_t11_list))\n",
    "\n",
    "zipped_tc_total_list=list(zip(years_tc_list,annual_rate_tc_list,stations_tc_list))\n",
    "zipped_ar_total_list=list(zip(years_ar_list,annual_rate_ar_list,stations_ar_list))\n",
    "zipped_other_total_list=list(zip(years_other_list,annual_rate_other_list,stations_other_list))\n",
    "\n",
    "trends_list_t1=[]\n",
    "trends_list_t2=[]\n",
    "trends_list_t3=[]\n",
    "trends_list_t4=[]\n",
    "trends_list_t5=[]\n",
    "trends_list_t6=[]\n",
    "trends_list_t7=[]\n",
    "trends_list_t8=[]\n",
    "trends_list_t9=[]\n",
    "trends_list_t10=[]\n",
    "trends_list_t11=[]\n",
    "\n",
    "trends_list_tc=[]\n",
    "trends_list_ar=[]\n",
    "trends_list_other=[]\n",
    "\n",
    "sigs_list_t1=[]\n",
    "sigs_list_t2=[]\n",
    "sigs_list_t3=[]\n",
    "sigs_list_t4=[]\n",
    "sigs_list_t5=[]\n",
    "sigs_list_t6=[]\n",
    "sigs_list_t7=[]\n",
    "sigs_list_t8=[]\n",
    "sigs_list_t9=[]\n",
    "sigs_list_t10=[]\n",
    "sigs_list_t11=[]\n",
    "\n",
    "sigs_list_tc=[]\n",
    "sigs_list_ar=[]\n",
    "sigs_list_other=[]\n",
    "\n",
    "sigs_list_t1a=[]\n",
    "sigs_list_t2a=[]\n",
    "sigs_list_t3a=[]\n",
    "sigs_list_t4a=[]\n",
    "sigs_list_t5a=[]\n",
    "sigs_list_t6a=[]\n",
    "sigs_list_t7a=[]\n",
    "sigs_list_t8a=[]\n",
    "sigs_list_t9a=[]\n",
    "sigs_list_t10a=[]\n",
    "sigs_list_t11a=[]\n",
    "\n",
    "sigs_list_tca=[]\n",
    "sigs_list_ara=[]\n",
    "sigs_list_othera=[]\n",
    "\n",
    "size_list_t1=[]\n",
    "size_list_t2=[]\n",
    "size_list_t3=[]\n",
    "size_list_t4=[]\n",
    "size_list_t5=[]\n",
    "size_list_t6=[]\n",
    "size_list_t7=[]\n",
    "size_list_t8=[]\n",
    "size_list_t9=[]\n",
    "size_list_t10=[]\n",
    "size_list_t11=[]\n",
    "size_list_tc=[]\n",
    "size_list_ar=[]\n",
    "size_list_other=[]\n",
    "\n",
    "means_t1_list=[]\n",
    "means_t2_list=[]\n",
    "means_t3_list=[]\n",
    "means_t4_list=[]\n",
    "means_t5_list=[]\n",
    "means_t6_list=[]\n",
    "means_t7_list=[]\n",
    "means_t8_list=[]\n",
    "means_t9_list=[]\n",
    "means_t10_list=[]\n",
    "means_t11_list=[]\n",
    "\n",
    "means_tc_list=[]\n",
    "means_ar_list=[]\n",
    "means_other_list=[]\n",
    "\n",
    "yrs_neusa=np.arange(1980,2020,1)\n",
    "for j in range(len(stations_station)):\n",
    "    print(j)\n",
    "    station=stations_station[j]\n",
    "    \n",
    "    select_t1=[x for x in zipped_t1_total_list if x[2]==station]\n",
    "    sorted_years_t1=sorted(select_t1,key=lambda x:x[0])\n",
    "    time_series_t1=[x[1] for x in sorted_years_t1]\n",
    "    print(time_series_t1)\n",
    "\n",
    "    select_t2=[x for x in zipped_t2_total_list if x[2]==station]\n",
    "    sorted_years_t2=sorted(select_t2,key=lambda x:x[0])\n",
    "    time_series_t2=[x[1] for x in sorted_years_t2]\n",
    "    \n",
    "    select_t3=[x for x in zipped_t3_total_list if x[2]==station]\n",
    "    sorted_years_t3=sorted(select_t3,key=lambda x:x[0])\n",
    "    time_series_t3=[x[1] for x in sorted_years_t3]\n",
    "    \n",
    "    select_t4=[x for x in zipped_t4_total_list if x[2]==station]\n",
    "    sorted_years_t4=sorted(select_t4,key=lambda x:x[0])\n",
    "    time_series_t4=[x[1] for x in sorted_years_t4]\n",
    "    \n",
    "    select_t5=[x for x in zipped_t5_total_list if x[2]==station]\n",
    "    sorted_years_t5=sorted(select_t5,key=lambda x:x[0])\n",
    "    time_series_t5=[x[1] for x in sorted_years_t5]\n",
    "    \n",
    "    select_t6=[x for x in zipped_t6_total_list if x[2]==station]\n",
    "    sorted_years_t6=sorted(select_t6,key=lambda x:x[0])\n",
    "    time_series_t6=[x[1] for x in sorted_years_t6]\n",
    "    \n",
    "    select_t7=[x for x in zipped_t7_total_list if x[2]==station]\n",
    "    sorted_years_t7=sorted(select_t7,key=lambda x:x[0])\n",
    "    time_series_t7=[x[1] for x in sorted_years_t7]\n",
    "    \n",
    "    select_t8=[x for x in zipped_t8_total_list if x[2]==station]\n",
    "    sorted_years_t8=sorted(select_t8,key=lambda x:x[0])\n",
    "    time_series_t8=[x[1] for x in sorted_years_t8]\n",
    "    \n",
    "    select_t9=[x for x in zipped_t9_total_list if x[2]==station]\n",
    "    sorted_years_t9=sorted(select_t9,key=lambda x:x[0])\n",
    "    time_series_t9=[x[1] for x in sorted_years_t9]\n",
    "    \n",
    "    select_t10=[x for x in zipped_t10_total_list if x[2]==station]\n",
    "    sorted_years_t10=sorted(select_t10,key=lambda x:x[0])\n",
    "    time_series_t10=[x[1] for x in sorted_years_t10]\n",
    "    \n",
    "    select_t11=[x for x in zipped_t11_total_list if x[2]==station]\n",
    "    sorted_years_t11=sorted(select_t11,key=lambda x:x[0])\n",
    "    time_series_t11=[x[1] for x in sorted_years_t11]\n",
    "    \n",
    "    select_tc=[x for x in zipped_tc_total_list if x[2]==station]\n",
    "    sorted_years_tc=sorted(select_tc,key=lambda x:x[0])\n",
    "    time_series_tc=[x[1] for x in sorted_years_tc]\n",
    "    \n",
    "    select_ar=[x for x in zipped_ar_total_list if x[2]==station]\n",
    "    sorted_years_ar=sorted(select_ar,key=lambda x:x[0])\n",
    "    time_series_ar=[x[1] for x in sorted_years_ar]\n",
    "    \n",
    "    select_other=[x for x in zipped_other_total_list if x[2]==station]\n",
    "    sorted_years_other=sorted(select_other,key=lambda x:x[0])\n",
    "    time_series_other=[x[1] for x in sorted_years_other]\n",
    "    \n",
    "    #---------\n",
    "    \n",
    "    annual_sum_mean_t1=float(sum(time_series_t1))/float(len(time_series_t1))\n",
    "    annual_sum_mean_t2=float(sum(time_series_t2))/float(len(time_series_t2))\n",
    "    annual_sum_mean_t3=float(sum(time_series_t3))/float(len(time_series_t3))\n",
    "    annual_sum_mean_t4=float(sum(time_series_t4))/float(len(time_series_t4))\n",
    "    annual_sum_mean_t5=float(sum(time_series_t5))/float(len(time_series_t5))\n",
    "    annual_sum_mean_t6=float(sum(time_series_t6))/float(len(time_series_t6))\n",
    "    annual_sum_mean_t7=float(sum(time_series_t7))/float(len(time_series_t7))\n",
    "    annual_sum_mean_t8=float(sum(time_series_t8))/float(len(time_series_t8))\n",
    "    annual_sum_mean_t9=float(sum(time_series_t9))/float(len(time_series_t9))\n",
    "    annual_sum_mean_t10=float(sum(time_series_t10))/float(len(time_series_t10))\n",
    "    annual_sum_mean_t11=float(sum(time_series_t11))/float(len(time_series_t11))\n",
    "    annual_sum_mean_tc=float(sum(time_series_tc))/float(len(time_series_tc))\n",
    "    annual_sum_mean_ar=float(sum(time_series_ar))/float(len(time_series_ar))\n",
    "    annual_sum_mean_other=float(sum(time_series_other))/float(len(time_series_other))\n",
    "    \n",
    "    means_t1_list.append(annual_sum_mean_t1)\n",
    "    means_t2_list.append(annual_sum_mean_t2)\n",
    "    means_t3_list.append(annual_sum_mean_t3)\n",
    "    means_t4_list.append(annual_sum_mean_t4)\n",
    "    means_t5_list.append(annual_sum_mean_t5)\n",
    "    means_t6_list.append(annual_sum_mean_t6)\n",
    "    means_t7_list.append(annual_sum_mean_t7)\n",
    "    means_t8_list.append(annual_sum_mean_t8)\n",
    "    means_t9_list.append(annual_sum_mean_t9)\n",
    "    means_t10_list.append(annual_sum_mean_t10)\n",
    "    means_t11_list.append(annual_sum_mean_t11)\n",
    "    \n",
    "    means_tc_list.append(annual_sum_mean_tc)\n",
    "    means_ar_list.append(annual_sum_mean_ar)\n",
    "    means_other_list.append(annual_sum_mean_other)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t1 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t1.append(1)\n",
    "    else:\n",
    "        size_list_t1.append(0)\n",
    "    trend=mk_test(time_series_t1,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t1,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t1)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t1*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t1.append(slope_percent)\n",
    "    sigs_list_t1.append(sig)\n",
    "    sigs_list_t1a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t2 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t2.append(1)\n",
    "    else:\n",
    "        size_list_t2.append(0)\n",
    "    trend=mk_test(time_series_t2,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t2,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t2)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t2*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t2.append(slope_percent)\n",
    "    sigs_list_t2.append(sig)\n",
    "    sigs_list_t2a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t3 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t3.append(1)\n",
    "    else:\n",
    "        size_list_t3.append(0)\n",
    "    trend=mk_test(time_series_t3,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t3,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t3)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t3*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t3.append(slope_percent)\n",
    "    sigs_list_t3.append(sig)\n",
    "    sigs_list_t3a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t4 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t4.append(1)\n",
    "    else:\n",
    "        size_list_t4.append(0)\n",
    "    trend=mk_test(time_series_t4,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t4,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t4)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t4*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t4.append(slope_percent)\n",
    "    sigs_list_t4.append(sig)\n",
    "    sigs_list_t4a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t5 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t5.append(1)\n",
    "    else:\n",
    "        size_list_t5.append(0)\n",
    "    trend=mk_test(time_series_t5,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t5,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t5)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t5*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t5.append(slope_percent)\n",
    "    sigs_list_t5.append(sig)\n",
    "    sigs_list_t5a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t6 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t6.append(1)\n",
    "    else:\n",
    "        size_list_t6.append(0)\n",
    "    trend=mk_test(time_series_t6,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t6,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t6)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t6*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t6.append(slope_percent)\n",
    "    sigs_list_t6.append(sig)\n",
    "    sigs_list_t6a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t7 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t7.append(1)\n",
    "    else:\n",
    "        size_list_t7.append(0)\n",
    "    trend=mk_test(time_series_t7,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t7,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t7)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t7*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t7.append(slope_percent)\n",
    "    sigs_list_t7.append(sig)\n",
    "    sigs_list_t7a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t8 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t8.append(1)\n",
    "    else:\n",
    "        size_list_t8.append(0)\n",
    "    trend=mk_test(time_series_t8,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t8,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t8)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t8*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t8.append(slope_percent)\n",
    "    sigs_list_t8.append(sig)\n",
    "    sigs_list_t8a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t9 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t9.append(1)\n",
    "    else:\n",
    "        size_list_t9.append(0)\n",
    "    trend=mk_test(time_series_t9,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t9,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t9)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t9*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t9.append(slope_percent)\n",
    "    sigs_list_t9.append(sig)\n",
    "    sigs_list_t9a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t10 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t10.append(1)\n",
    "    else:\n",
    "        size_list_t10.append(0)\n",
    "    trend=mk_test(time_series_t10,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t10,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t10)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t10*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t10.append(slope_percent)\n",
    "    sigs_list_t10.append(sig)\n",
    "    sigs_list_t10a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_t11 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t11.append(1)\n",
    "    else:\n",
    "        size_list_t11.append(0)\n",
    "    trend=mk_test(time_series_t11,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_t11,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_t11)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t11*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t11.append(slope_percent)\n",
    "    sigs_list_t11.append(sig)\n",
    "    sigs_list_t11a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_tc if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_tc.append(1)\n",
    "    else:\n",
    "        size_list_tc.append(0)\n",
    "    trend=mk_test(time_series_tc,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_tc,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_tc)[0]\n",
    "    slope_percent=slope/annual_sum_mean_tc*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_tc.append(slope_percent)\n",
    "    sigs_list_tc.append(sig)\n",
    "    sigs_list_tca.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_ar if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_ar.append(1)\n",
    "    else:\n",
    "        size_list_ar.append(0)\n",
    "    trend=mk_test(time_series_ar,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_ar,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_ar)[0]\n",
    "    slope_percent=slope/annual_sum_mean_ar*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_ar.append(slope_percent)\n",
    "    sigs_list_ar.append(sig)\n",
    "    sigs_list_ara.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in time_series_other if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_other.append(1)\n",
    "    else:\n",
    "        size_list_other.append(0)\n",
    "    trend=mk_test(time_series_other,alpha=0.05)[0]\n",
    "    trenda=mk_test(time_series_other,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,time_series_other)[0]\n",
    "    slope_percent=slope/annual_sum_mean_other*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_other.append(slope_percent)\n",
    "    sigs_list_other.append(sig)\n",
    "    sigs_list_othera.append(siga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "clon=-70\n",
    "clat=35\n",
    "proj_map = ccrs.LambertConformal(central_longitude=clon, central_latitude=clat)\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "ax=plt.subplot(1,1,1,projection=proj_map)\n",
    "\n",
    "ax.coastlines(resolution='10m')\n",
    "ax.add_feature(cfeature.STATES.with_scale('10m'),alpha=0.3)\n",
    "ax.add_feature(cfeature.LAKES.with_scale('50m'))\n",
    "countries = cfeature.NaturalEarthFeature(category='cultural',name='admin_0_boundary_lines_land',scale='50m',facecolor='none')\n",
    "ax.add_feature(countries)\n",
    "ax.set_extent([-84,-66,36,48],crs=ccrs.PlateCarree())\n",
    "\n",
    "sigs_list=sigs_list_t11.copy()\n",
    "sigs_lista=sigs_list_t11a.copy()\n",
    "trends_list=trends_list_t11.copy()\n",
    "size_list=size_list_t11.copy()\n",
    "\n",
    "print(size_list)\n",
    "\n",
    "if 1==1:\n",
    "    for i in range(len(sigs_list)):\n",
    "        if size_list[i]==0:\n",
    "            trends_list[i]=np.nan\n",
    "        \n",
    "for i in range(len(sigs_lista)):\n",
    "    sig=sigs_lista[i]\n",
    "    if sig in [-1,1] and size_list[i]==1:#convert to mm\n",
    "        ax.plot(lons_station[i],lats_station[i],transform=ccrs.PlateCarree(),marker='o',markerfacecolor='None',markeredgecolor='grey',markeredgewidth=2,markersize=28)\n",
    "    \n",
    "for i in range(len(sigs_list)):\n",
    "    sig=sigs_list[i]\n",
    "    if sig in [-1,1] and size_list[i]==1:#convert to mm\n",
    "        ax.plot(lons_station[i],lats_station[i],transform=ccrs.PlateCarree(),marker='o',markerfacecolor='None',markeredgecolor='k',markeredgewidth=2,markersize=28)\n",
    "    \n",
    "# *must* call draw in order to get the axis boundary used to add ticks:\n",
    "fig.canvas.draw()\n",
    "\n",
    "#zipped_t1=list(zip(dates,ar_yesno4))#ar-related = green\n",
    "#zipped_t2=list(zip(dates,tc_linked_ar_yesno4))\n",
    "#zipped_t3=list(zip(dates,tc_remnant_linked_ar_yesno4))\n",
    "#zipped_t4=list(zip(dates,tc_yesno4))#tc-related = blue\n",
    "#zipped_t5=list(zip(dates,tc_ar_combo_yesno4))\n",
    "#zipped_t6=list(zip(dates,tc_remnant_ar_combo_yesno4))\n",
    "#zipped_t7=list(zip(dates,tc_remnants_yesno4))\n",
    "#zipped_t8=list(zip(dates,ivt_yesno4))#other IVT-related = grey\n",
    "#zipped_t9=list(zip(dates,tc_linked_ivt_yesno4))\n",
    "#zipped_t10=list(zip(dates,tc_remnant_linked_ivt_yesno4))\n",
    "#zipped_t11=list(zip(dates,other_yesno4))#unspecified = brown\n",
    "\n",
    "# Define gridline locations and draw the lines using cartopy's built-in gridliner:\n",
    "xticks = [-90,-85,-80,-75,-70,-65,-60,-50]\n",
    "yticks = [5,10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "ax.gridlines(xlocs=xticks, ylocs=yticks,alpha=0.5)\n",
    "ax.tick_params(labelsize=26)\n",
    "# Label the end-points of the gridlines using the custom tick makers:\n",
    "ax.xaxis.set_major_formatter(LONGITUDE_FORMATTER) \n",
    "ax.yaxis.set_major_formatter(LATITUDE_FORMATTER)\n",
    "lambert_xticks(ax, xticks)\n",
    "lambert_yticks(ax, yticks)\n",
    "cax=ax.scatter(lons_station,lats_station,s=240,c=trends_list,transform=ccrs.PlateCarree(),vmin=-4.5,vmax=4.5,cmap=plt.cm.seismic_r,zorder=10)\n",
    "for i in range(len(trends_list)):\n",
    "    lon=lons_station[i]\n",
    "    lat=lats_station[i]\n",
    "    size=size_list[i]\n",
    "    if size==0:\n",
    "    #if 1==1:\n",
    "        if trends_list[i]>0:\n",
    "            print('POS')\n",
    "            ax.plot(lon,lat,marker='+',transform=ccrs.PlateCarree(),markersize=8,color='k')\n",
    "        if trends_list[i]<0:\n",
    "            print('NEG')\n",
    "            ax.plot(lon,lat,marker='_',transform=ccrs.PlateCarree(),markersize=8,color='k')\n",
    "cbar=plt.colorbar(cax,pad=0,extend='both',fraction=0.046)\n",
    "cbar.ax.tick_params(labelsize=28)\n",
    "cbar.set_label('% yr$^{-1}$',fontsize=28,rotation=90,labelpad=15)\n",
    "ax.set_title('Trend',fontsize=46,pad=10)\n",
    "#props = dict(boxstyle='round', facecolor='wheat', alpha=1.0)\n",
    "#ax.text(0.01, 0.99,'n='+str(len(dates_list)), transform=ax.transAxes, fontsize=28,verticalalignment='top', bbox=props)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'two_week_paper_geotrends_43.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "clon=-70\n",
    "clat=35\n",
    "proj_map = ccrs.LambertConformal(central_longitude=clon, central_latitude=clat)\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "ax=plt.subplot(1,1,1,projection=proj_map)\n",
    "\n",
    "ax.coastlines(resolution='10m')\n",
    "ax.add_feature(cfeature.STATES.with_scale('10m'),alpha=0.3)\n",
    "ax.add_feature(cfeature.LAKES.with_scale('50m'))\n",
    "countries = cfeature.NaturalEarthFeature(category='cultural',name='admin_0_boundary_lines_land',scale='50m',facecolor='none')\n",
    "ax.add_feature(countries)\n",
    "ax.set_extent([-84,-66,36,48],crs=ccrs.PlateCarree())\n",
    "\n",
    "means_list=means_t11_list\n",
    "\n",
    "# *must* call draw in order to get the axis boundary used to add ticks:\n",
    "fig.canvas.draw()\n",
    "\n",
    "# Define gridline locations and draw the lines using cartopy's built-in gridliner:\n",
    "xticks = [-90,-85,-80,-75,-70,-65,-60,-50]\n",
    "yticks = [5,10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "ax.gridlines(xlocs=xticks, ylocs=yticks,alpha=0.5)\n",
    "ax.tick_params(labelsize=26)\n",
    "# Label the end-points of the gridlines using the custom tick makers:\n",
    "ax.xaxis.set_major_formatter(LONGITUDE_FORMATTER) \n",
    "ax.yaxis.set_major_formatter(LATITUDE_FORMATTER)\n",
    "lambert_xticks(ax, xticks)\n",
    "lambert_yticks(ax, yticks)\n",
    "cax=ax.scatter(lons_station,lats_station,s=240,c=means_list,transform=ccrs.PlateCarree(),vmin=0,vmax=50,cmap=plt.cm.Greens,zorder=10)\n",
    "\n",
    "#cbar=plt.colorbar(cax,pad=0,extend='max',fraction=0.046,ticks=[10,20,30,40,50,60,70])\n",
    "#cbar=plt.colorbar(cax,pad=0,extend='max',fraction=0.046,ticks=[4,8,12,16,20])\n",
    "#cbar=plt.colorbar(cax,pad=0,extend='max',fraction=0.046,ticks=[8,16,24,32,40])\n",
    "cbar=plt.colorbar(cax,pad=0,extend='max',fraction=0.046,ticks=[10,20,30,40,50])\n",
    "cbar.ax.tick_params(labelsize=28)\n",
    "cbar.set_label('mm yr$^{-1}$',fontsize=28,rotation=90,labelpad=15)\n",
    "#ax.set_title('Annual rate',fontsize=46,pad=10)\n",
    "ax.set_title('Winter',fontsize=46,pad=15)\n",
    "#props = dict(boxstyle='round', facecolor='wheat', alpha=1.0)\n",
    "#ax.text(0.01, 0.99,'n='+str(len(dates_list)), transform=ax.transAxes, fontsize=28,verticalalignment='top', bbox=props)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'two_week_paper_geotrends_41a.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f0611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
