{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import os,errno\n",
    "import sys\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'\n",
    "\n",
    "#This script plots trends *season total* 95th percentile precip (no weather type subdivision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-upset",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 1==1:#part 2: read the obs at eligible stations into a better format\n",
    "    yr_start=1979\n",
    "    yr_end=2019\n",
    "    tuples=[]\n",
    "    years=[]\n",
    "    months=[]\n",
    "    days1=[]\n",
    "    lats1=[]\n",
    "    lons1=[]\n",
    "    elevs1=[]\n",
    "    observations=[]\n",
    "    dates=[]\n",
    "    station_names_list=[]\n",
    "    stations_list=[]\n",
    "    dp=xr.open_dataset(dir+'station_numbers_95.nc')\n",
    "    stations=dp.stations.values.tolist()\n",
    "    lats=dp.lats.values.tolist()\n",
    "    lons=dp.lons.values.tolist()\n",
    "    elevs=dp.elevs.values.tolist()\n",
    "    station_names=dp.station_names.values.tolist()\n",
    "    points=zip(lons,lats)\n",
    "    for i in range(len(stations)):\n",
    "        print(str(i+1)+'/'+str(len(stations)))\n",
    "        lat=lats[i]\n",
    "        lon=lons[i]\n",
    "        elev=elevs[i]\n",
    "        station_name=station_names[i]\n",
    "        station=stations[i]\n",
    "        filename=stations[i]\n",
    "        ds1=pd.read_csv(filename,header=None)\n",
    "        nancount=0\n",
    "        qcount=0\n",
    "        yescount=0\n",
    "        for row1 in ds1.iterrows():\n",
    "            row_neg_space=row1[1][0].replace('-',' -')\n",
    "            row_basic=row1[1][0]\n",
    "            a=row_neg_space.split()\n",
    "            code=a[0][-4:]\n",
    "            if code=='PRCP':\n",
    "                year=int(a[0][11:15])\n",
    "                if yr_start<=year<=yr_end:\n",
    "                    month=int(a[0][15:17])\n",
    "                    if month in [1,3,5,7,8,10,12]:\n",
    "                        days=31\n",
    "                    if month in [4,6,9,11]:\n",
    "                        days=30\n",
    "                    if month==2 and year%4==0:\n",
    "                        days=29\n",
    "                    if month==2 and year%4!=0:\n",
    "                        days=28\n",
    "\n",
    "                    for i in range(days):\n",
    "                        #print(row_basic)\n",
    "                        mflag=row_basic[26+8*i]\n",
    "                        qflag=row_basic[27+8*i]\n",
    "                        sflag=row_basic[28+8*i]\n",
    "                        obs=float(row_basic[21+8*i:26+8*i])\n",
    "                    \n",
    "                        if obs==-9999.0:\n",
    "                            pass\n",
    "                        elif qflag!=' ':\n",
    "                            pass\n",
    "                        else:\n",
    "                            years.append(year)\n",
    "                            months.append(month)\n",
    "                            days1.append(i)\n",
    "                            observations.append(obs/10.)#convert from tenths of mm to mm\n",
    "                            lats1.append(lat)\n",
    "                            lons1.append(lon)\n",
    "                            elevs1.append(elev)\n",
    "                            date=dt.datetime(year,month,i+1,6)\n",
    "                            dates.append(date)\n",
    "                            station_names_list.append(station_name)\n",
    "                            stations_list.append(station)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_unique=list(set(dates))\n",
    "dates_unique=pd.DatetimeIndex(dates_unique).sort_values()\n",
    "print(dates_unique)\n",
    "stations=stations_list\n",
    "obs=observations\n",
    "print(max(obs))\n",
    "\n",
    "ds1=xr.open_dataset(dir+'station_numbers_95.nc')\n",
    "lats_station=ds1['lats']#use these lists for plotting\n",
    "lons_station=ds1['lons']\n",
    "stations_station=ds1['stations']\n",
    "print(stations_station)\n",
    "\n",
    "thresholds_winter_99=ds1['thresholds_winter_99']/10.\n",
    "thresholds_spring_99=ds1['thresholds_spring_99']/10.\n",
    "thresholds_summer_99=ds1['thresholds_summer_99']/10.\n",
    "thresholds_fall_99=ds1['thresholds_fall_99']/10.\n",
    "\n",
    "thresholds_winter_95=ds1['thresholds_winter_95']/10.\n",
    "thresholds_spring_95=ds1['thresholds_spring_95']/10.\n",
    "thresholds_summer_95=ds1['thresholds_summer_95']/10.\n",
    "thresholds_fall_95=ds1['thresholds_fall_95']/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import shapely.geometry as sgeom\n",
    "def find_side(ls, side):\n",
    "    \"\"\"\n",
    "    Given a shapely LineString which is assumed to be rectangular, return the\n",
    "    line corresponding to a given side of the rectangle.\n",
    "    \n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = ls.bounds\n",
    "    points = {'left': [(minx, miny), (minx, maxy)],\n",
    "              'right': [(maxx, miny), (maxx, maxy)],\n",
    "              'bottom': [(minx, miny), (maxx, miny)],\n",
    "              'top': [(minx, maxy), (maxx, maxy)],}\n",
    "    return sgeom.LineString(points[side])\n",
    "\n",
    "\n",
    "def lambert_xticks(ax, ticks):\n",
    "    \"\"\"Draw ticks on the bottom x-axis of a Lambert Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[0]\n",
    "    lc = lambda t, n, b: np.vstack((np.zeros(n) + t, np.linspace(b[2], b[3], n))).T\n",
    "    xticks, xticklabels = _lambert_ticks(ax, ticks, 'bottom', lc, te)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels([ax.xaxis.get_major_formatter()(xtick) for xtick in xticklabels])\n",
    "    \n",
    "\n",
    "def lambert_yticks(ax, ticks):\n",
    "    \"\"\"Draw ricks on the left y-axis of a Lamber Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[1]\n",
    "    lc = lambda t, n, b: np.vstack((np.linspace(b[0], b[1], n), np.zeros(n) + t)).T\n",
    "    yticks, yticklabels = _lambert_ticks(ax, ticks, 'left', lc, te)\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([ax.yaxis.get_major_formatter()(ytick) for ytick in yticklabels])\n",
    "def _lambert_ticks(ax, ticks, tick_location, line_constructor, tick_extractor):\n",
    "    \"\"\"Get the tick locations and labels for an axis of a Lambert Conformal projection.\"\"\"\n",
    "    outline_patch = sgeom.LineString(ax.outline_patch.get_path().vertices.tolist())\n",
    "    axis = find_side(outline_patch, tick_location)\n",
    "    n_steps = 30\n",
    "    extent = ax.get_extent(ccrs.PlateCarree())\n",
    "    _ticks = []\n",
    "    for t in ticks:\n",
    "        xy = line_constructor(t, n_steps, extent)\n",
    "        proj_xyz = ax.projection.transform_points(ccrs.Geodetic(), xy[:, 0], xy[:, 1])\n",
    "        xyt = proj_xyz[..., :2]\n",
    "        ls = sgeom.LineString(xyt.tolist())\n",
    "        locs = axis.intersection(ls)\n",
    "        if not locs:\n",
    "            tick = [None]\n",
    "        else:\n",
    "            tick = tick_extractor(locs.xy)\n",
    "        _ticks.append(tick[0])\n",
    "    # Remove ticks that aren't visible:    \n",
    "    ticklabels = copy(ticks)\n",
    "    while True:\n",
    "        try:\n",
    "            index = _ticks.index(None)\n",
    "        except ValueError:\n",
    "            break\n",
    "        _ticks.pop(index)\n",
    "        ticklabels.pop(index)\n",
    "    return _ticks, ticklabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import scipy.stats as st\n",
    "def mk_test(x, alpha=0.05):\n",
    "    n = len(x)\n",
    "\n",
    "    # calculate S\n",
    "    s = 0\n",
    "    for k in range(n-1):\n",
    "        for j in range(k+1, n):\n",
    "            s += np.sign(x[j] - x[k])\n",
    "\n",
    "    # calculate the unique data\n",
    "    unique_x, tp = np.unique(x, return_counts=True)\n",
    "    g = len(unique_x)\n",
    "\n",
    "    # calculate the var(s)\n",
    "    if n == g:  # there is no tie\n",
    "        var_s = (n*(n-1)*(2*n+5))/18\n",
    "    else:  # there are some ties in data\n",
    "        var_s = (n*(n-1)*(2*n+5) - np.sum(tp*(tp-1)*(2*tp+5)))/18\n",
    "\n",
    "    if s > 0:\n",
    "        z = (s - 1)/np.sqrt(var_s)\n",
    "    elif s < 0:\n",
    "        z = (s + 1)/np.sqrt(var_s)\n",
    "    else: # s == 0:\n",
    "        z = 0\n",
    "\n",
    "    # calculate the p_value\n",
    "    p = 2*(1-norm.cdf(abs(z)))  # two tail test\n",
    "    h = abs(z) > norm.ppf(1-alpha/2)\n",
    "\n",
    "    if (z < 0) and h:\n",
    "        trend = 'decreasing'\n",
    "    elif (z > 0) and h:\n",
    "        trend = 'increasing'\n",
    "    else:\n",
    "        trend = 'no trend'\n",
    "\n",
    "    return trend, h, p, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-california",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yrs_neusa=np.arange(1979,2020,1)\n",
    "zipped=list(zip(dates,stations_list,lats1,lons1,observations))\n",
    "trends_list=[]\n",
    "sigs_list=[]\n",
    "sigs_lista=[]\n",
    "print(len(zipped))\n",
    "for i in range(len(stations_station)):\n",
    "    print(i)\n",
    "    station=stations_station[i].values\n",
    "    select_station=[x for x in zipped if x[1]==station]\n",
    "    threshold=thresholds_winter_95[i]\n",
    "    annual_sum_list=[]\n",
    "    for j in range(1,len(yrs_neusa)):\n",
    "        year=yrs_neusa[j]\n",
    "        if 1==0:\n",
    "            select_station_year=[x for x in select_station if pd.to_datetime(x[0]).year==year and pd.to_datetime(x[0]).month in [3,4,5]]\n",
    "        if 1==1:\n",
    "            year_prev=yrs_neusa[j-1]\n",
    "            select_station_year_prev=[x for x in select_station if pd.to_datetime(x[0]).year==year_prev and pd.to_datetime(x[0]).month==12]\n",
    "            select_station_year_current=[x for x in select_station if pd.to_datetime(x[0]).year==year and pd.to_datetime(x[0]).month in [1,2]]\n",
    "            select_station_year=select_station_year_prev+select_station_year_current\n",
    "        \n",
    "        if len(select_station_year)>0:\n",
    "            select_obs=[x[-1] for x in select_station_year]\n",
    "            measurable=[x for x in select_obs if x>=threshold]\n",
    "            annual_sum=sum(measurable)\n",
    "            annual_sum_list.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list.append(0)\n",
    "    annual_sum_mean=float(sum(annual_sum_list))/float(len(annual_sum_list))\n",
    "    trend=mk_test(annual_sum_list,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa[1:],annual_sum_list)[0]\n",
    "    slope_percent=slope/annual_sum_mean*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list.append(slope_percent)\n",
    "    sigs_list.append(sig)\n",
    "    sigs_lista.append(siga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trends_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "clon=-70\n",
    "clat=35\n",
    "proj_map = ccrs.LambertConformal(central_longitude=clon, central_latitude=clat)\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "ax=plt.subplot(1,1,1,projection=proj_map)\n",
    "\n",
    "ax.coastlines(resolution='10m')\n",
    "ax.add_feature(cfeature.STATES.with_scale('10m'),alpha=0.3)\n",
    "ax.add_feature(cfeature.LAKES.with_scale('50m'))\n",
    "countries = cfeature.NaturalEarthFeature(category='cultural',name='admin_0_boundary_lines_land',scale='50m',facecolor='none')\n",
    "ax.add_feature(countries)\n",
    "ax.set_extent([-84,-66,36,48],crs=ccrs.PlateCarree())\n",
    "\n",
    "for i in range(len(sigs_lista)):\n",
    "    sig=sigs_lista[i]\n",
    "    if sig in [-1,1]:#convert to mm\n",
    "        ax.plot(lons_station[i],lats_station[i],transform=ccrs.PlateCarree(),marker='o',markerfacecolor='None',markeredgecolor='grey',markeredgewidth=2,markersize=28)\n",
    "\n",
    "for i in range(len(sigs_list)):\n",
    "    sig=sigs_list[i]\n",
    "    if sig in [-1,1]:#convert to mm\n",
    "        ax.plot(lons_station[i],lats_station[i],transform=ccrs.PlateCarree(),marker='o',markerfacecolor='None',markeredgecolor='k',markeredgewidth=2,markersize=28)\n",
    "    \n",
    "# *must* call draw in order to get the axis boundary used to add ticks:\n",
    "fig.canvas.draw()\n",
    "\n",
    "# Define gridline locations and draw the lines using cartopy's built-in gridliner:\n",
    "xticks = [-90,-85,-80,-75,-70,-65,-60,-50]\n",
    "yticks = [5,10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "ax.gridlines(xlocs=xticks, ylocs=yticks,alpha=0.5)\n",
    "ax.tick_params(labelsize=26)\n",
    "# Label the end-points of the gridlines using the custom tick makers:\n",
    "ax.xaxis.set_major_formatter(LONGITUDE_FORMATTER) \n",
    "ax.yaxis.set_major_formatter(LATITUDE_FORMATTER)\n",
    "lambert_xticks(ax, xticks)\n",
    "lambert_yticks(ax, yticks)\n",
    "cax=ax.scatter(lons_station,lats_station,s=240,c=trends_list,transform=ccrs.PlateCarree(),vmin=-4,vmax=4,cmap=plt.cm.seismic_r,zorder=10)\n",
    "cbar=plt.colorbar(cax,pad=0,extend='both',fraction=0.046)\n",
    "cbar.ax.tick_params(labelsize=28)\n",
    "cbar.set_label('% yr$^{-1}$',fontsize=28,rotation=90,labelpad=15)\n",
    "ax.set_title('Winter',fontsize=46,pad=15)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=1.0)\n",
    "#ax.text(0.01, 0.99,'n='+str(len(trends_list)), transform=ax.transAxes, fontsize=28,verticalalignment='top', bbox=props)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'climo_neusa_seasonal_trends_winter'+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-suspect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
